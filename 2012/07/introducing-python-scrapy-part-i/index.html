<!DOCTYPE html>
<html lang="zh">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html" />
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="author" content="Kane Dou">
<link rel="shortcut icon" href="/favicon.ico">
<link href="/feed.xml" rel="alternate" title="kandou.me" type="application/rss+xml">
<link rel="stylesheet" href="/assets/stylesheets/screen.css" />
<link rel="stylesheet" href="/assets/stylesheets/syntax.css" />
<title>
  使用 scrapy （Part I） | kanedou.me
</title>

  </head>
  <body>
    <div class="container">
      <header>
        <div class="row">
          <section class="site-name">
            <div class="span2">
              <h1><a href="/">kanedou.me</a></h1>
            </div>
          </section>
          <section class="nav">
            <div class="span4">
              <nav role="navigation">
  <ul class="nav nav-pills">
    <li><a href="/archive.html">archive</a></li>
    <li><a href="/links.html">links</a></li>
    <li><a href="/about.html">about</a></li>
    <li><a href="/feed.xml">feed</a></li>
  </ul>
</nav>

            </div>
          </section>
        </div>
      </header>
      <div id="content">
        
<article role="article" class="well">
  <header>
    <section class="title">
      <h1>
        
        使用 scrapy （Part I）
        
      </h1>
    </section>
    <section class="meta">
      @<time>2012-07-18</time>
      <span class="categories">
        
        <em class="category">#python</em>
        
        <em class="category">#scrape</em>
        
        <em class="category">#crawl</em>
        
        <em class="category">#scrapy</em>
        
        <em class="category">#twisted</em>
        
      </span>
    </section>
  </header>
  <section class="post">
    <p><a href="http://scrapy.org">scrapy</a> 是一个高级的网页内容抓取工具，主要用来自动化访问网
页并程序化提取其中对用户有用的内容。scrapy 构建于流行的 python 异步框架
<a href="http://twistedmatrix.com">twisted</a> 之上，利用该框架的特点达到抓取的高效率，但
其面向用户的接口则是完全经过封装并与普通 python 代码写法并无二致的，因此不熟悉
twisted 的用户也不用担心。</p>

<!-- more -->


<h2>安装</h2>

<p>由于 scrapy 是一个 python package，所以先安装 virtualenv 及 pip：</p>

<div class="highlight"><pre><code class="sh"><span class="nv">$ </span>sudo apt-get install virtualenv python-pip
</code></pre></div>


<p>接着安装 scrapy：</p>

<div class="highlight"><pre><code class="sh"><span class="nv">$ </span>virtualenv --no-site-packages scrapy
<span class="nv">$ </span><span class="nb">source</span> ./scrapy/bin/activate
<span class="nv">$ </span>pip install scrapy
</code></pre></div>


<h2>使用</h2>

<p>scrapy 提供的各种工具能大量简化实际抓取时的代码量，同时其对抓取过程的抽象化也很
到位，方便用户对其控制的同时也提供了相当的自动化特性。</p>

<p>这里就用罗森的官方网站（http://www.lawson.com.cn/shops）为例，说明一下如何使用
scrapy。示例的结果是得到一份罗森在上海的所有便利店的清单。</p>

<h3>新建 Project</h3>

<p>首先用 scrapy 新建一个 project：</p>

<div class="highlight"><pre><code class="sh"><span class="nv">$ </span>scrapy startproject lawson
</code></pre></div>


<p>熟悉一下目录结构：</p>

<div class="highlight"><pre><code class="text">lawson
├── lawson
│   ├── __init__.py
│   ├── items.py
│   ├── pipelines.py
│   ├── settings.py
│   └── spiders
│       └── __init__.py
└── scrapy.cfg
</code></pre></div>


<ul>
<li><code>items.py</code> 定义抓取结果中单个项所需要包含的所有内容，比如便利店的地址、
分店名称等。</li>
<li><code>pipelines.py</code> 定义如何对抓取到的内容进行再处理，例如输出文件、写入数据库等。</li>
<li><code>settings.py</code> 是 scrapy 的设置文件，可对其行为进行调整。</li>
<li><code>spiders</code> 目录下存放写好的 spider，也即是实际抓取逻辑。</li>
<li><code>scrapy.cfg</code> 是整个项目的设置，主要用于部署 scrapyd 服务，本文不会涉及。</li>
</ul>


<h3>第一个 spider</h3>

<p>scrapy 中最为重要的部分就是
<a href="http://doc.scrapy.org/en/0.14/topics/spiders.html">spider</a>。它包含了
分析网页与抓取网页数据的具体逻辑，也就是说对网页上任何内容的任何处理都在 spider
中实现。因此，这是 scrapy 整个框架的核心。</p>

<p>首先定义
<a href="http://doc.scrapy.org/en/0.14/topics/items.html#module-scrapy.item">Item</a>：</p>

<div class="highlight"><pre><code class="python"><span class="kn">from</span> <span class="nn">scrapy.item</span> <span class="kn">import</span> <span class="n">Item</span><span class="p">,</span> <span class="n">Field</span>


<span class="k">class</span> <span class="nc">ConvStore</span><span class="p">(</span><span class="n">Item</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">branch</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">alias</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">address</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">city</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">district</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">longitude</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="n">serializer</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">latitude</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="n">serializer</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</code></pre></div>


<p>这里定义了一个便利店（<code>ConvStore</code>）所应包含的内容（
<a href="http://doc.scrapy.org/en/0.14/topics/items.html#item-fields">Field</a> ），会在
spider 中用到，用来承载其抓取下来的实际数据。</p>

<p>现在来看 spider：</p>

<div class="highlight"><pre><code class="python"><span class="kn">from</span> <span class="nn">scrapy.contrib.linkextractors.sgml</span> <span class="kn">import</span> <span class="n">SgmlLinkExtractor</span>
<span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">CrawlSpider</span><span class="p">,</span> <span class="n">Rule</span>
<span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">HtmlXPathSelector</span>

<span class="kn">from</span> <span class="nn">lawson.items</span> <span class="kn">import</span> <span class="n">ConvStore</span>


<span class="k">class</span> <span class="nc">LawsonSpider</span><span class="p">(</span><span class="n">CrawlSpider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&#39;lawson&#39;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.lawson.com.cn/shops&#39;</span><span class="p">]</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;lawson.com.cn&#39;</span><span class="p">]</span>
    <span class="n">rules</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">Rule</span><span class="p">(</span><span class="n">SgmlLinkExtractor</span><span class="p">(</span><span class="n">allow</span><span class="o">=</span><span class="s">r&#39;list\?area_id=\d+&#39;</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="s">&#39;a&#39;</span><span class="p">),</span>
                <span class="n">callback</span><span class="o">=</span><span class="s">&#39;parse_store_list&#39;</span><span class="p">),</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse_store_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">hxs</span> <span class="o">=</span> <span class="n">HtmlXPathSelector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="n">store_selectors</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;//div[@class=&quot;ShopList&quot;]/table/tr&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>

        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">store_selectors</span><span class="p">:</span>
            <span class="n">store</span> <span class="o">=</span> <span class="n">ConvStore</span><span class="p">()</span>
            <span class="n">store</span><span class="p">[</span><span class="s">&#39;name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s">u&#39;罗森&#39;</span>
            <span class="n">store</span><span class="p">[</span><span class="s">&#39;alias&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s">u&#39;Lawson&#39;</span>
            <span class="n">store</span><span class="p">[</span><span class="s">&#39;branch&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;th/p/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
            <span class="n">store</span><span class="p">[</span><span class="s">&#39;address&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;td/span/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
            <span class="n">store</span><span class="p">[</span><span class="s">&#39;district&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s">&#39;link_text&#39;</span><span class="p">]</span>
            <span class="n">store</span><span class="p">[</span><span class="s">&#39;city&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s">u&#39;上海&#39;</span>

            <span class="k">yield</span> <span class="n">store</span><span class="o">.</span><span class="n">load_item</span><span class="p">()</span>
</code></pre></div>


<ul>
<li>首先可以看到代码很短，整个 <code>LawsonSpider</code> 类只有二十多行，但已经能够为我们抓
取所有必需的信息。</li>
<li>scrapy 提供了一些基本类（Base class）让我们去继承，
<a href="http://doc.scrapy.org/en/0.14/topics/spiders.html#crawlspider"><code>CrawlSpider</code></a>
就是其中之一。代码中所定义的类变量（Class variable）都是再 scrapy 中有各自作
用的。

<ul>
<li><code>name</code> 是该 spider 的名字，scrapy 命令行工具调用 spider 时就用这个名字去找
到对应的 spider。</li>
<li><code>start_urls</code> 是 spider 的入口，即是告诉它该从哪个网页开始抓取。</li>
<li><code>allowed_domains</code> 限定 spider 的抓取活动只能在指定的 domain 中进行。</li>
</ul>
</li>
<li><code>rules</code> 定义了一系列规则用来匹配网页中出现的内容，并根据规则分发至不同的处理
方法中。这里定义了一个规则是向网页中所有匹配正则表达式 <code>r'list\?area_id=\d+'</code>
的链接（如果你在浏览器打开初始页面的话会发现这些就是页面下方以上海各个区命名
的那几个链接）发出请求并将其结果交给 <code>parse_store_list</code> 方法（Method）来处理。</li>
<li><a href="http://doc.scrapy.org/en/0.14/topics/link-extractors.html#sgmllinkextractor"><code>SgmlLinkExtractor</code></a>
是 scrapy 提供的连接提取器，它的用途就是，呃，提取链接。

<ul>
<li><code>allow</code> 参数是正则表达式，网页中匹配的链接会被抓取。</li>
<li><code>tags</code> 指定从哪些标签抓取链接，默认 <code>['a', 'area']</code>（通过分析网页
这里不能包含 <code>area</code>，故手动指定。</li>
</ul>
</li>
<li><code>parse_store_list</code> 方法定义了如何抓取特定网页中的数据

<ul>
<li><a href="http://doc.scrapy.org/en/0.14/topics/selectors.html#scrapy.selector.HtmlXPathSelector"><code>HtmlXPathSelector</code></a>
是一个选择器，使用它能方便地定位到网页中的某个位置并抓取其中内容。</li>
</ul>
</li>
</ul>


<h3><code>CrawlSpider</code></h3>

<p>这个类是整个抓取逻辑的基础，他的工作流程如下：</p>

<ol>
<li>若有 <code>start_urls</code>，则从这些 URL 开始抓取，若没有，则执行 <code>start_requests</code> 方
法（用户须定义），并请求该方法返回的 <code>Request</code> 对象，并从这些请求结果中开始
抓取。</li>
<li>所有网页请求返回的 <code>Response</code> 默认交给 <code>parse</code> 方法处理。

<ul>
<li><code>parse</code> 方法在 <code>CrawlSpider</code> 的默认实现是用已定义的 <code>rules</code> 对获得的网页内
容进行匹配并进行由 <code>Rule</code> 所指定的进一步处理（即交给 <code>callback</code> 参数所指定
的 <code>callable</code> 去处理）。</li>
<li>若不指定 <code>callback</code>, <code>Rule</code> 的默认处理是对匹配的网址发起请求，并再次交给
<code>parse</code>。</li>
</ul>
</li>
<li>任何方法中返回的 Item 实例（如示例中的 <code>ConvStore</code>）都会被作为有效数据保存
（输出文件等），再处理（
<a href="http://doc.scrapy.org/en/0.14/topics/item-pipeline.html">Pipeline</a>）。</li>
</ol>


<h3><code>HtmlXPathSelector</code></h3>

<p>这是一个通过 <a href="http://www.w3schools.com/xpath/default.asp">XPath</a> 对 HTML 页面进
行结构化定位和内容读取的工具。scrapy 使用它定位到网页中用户所需要的数据并进行抓
取。</p>

<div class="highlight"><pre><code class="python"><span class="k">def</span> <span class="nf">parse_store_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
    <span class="n">hxs</span> <span class="o">=</span> <span class="n">HtmlXPathSelector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
    <span class="n">store_selectors</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;//div[@class=&quot;ShopList&quot;]/table/tr&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>

    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">store_selectors</span><span class="p">:</span>
        <span class="o">...</span>
        <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;branch&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;th/p/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">())</span>
        <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;address&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;td/span/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">())</span>
        <span class="o">...</span>
</code></pre></div>


<ul>
<li><code>HtmlXPathSelector</code> 需要一个 Response 对象来实例化。</li>
<li><code>//div[@class="ShopList"]/table/tr</code> 选择了所有包含罗森门店信息的 <code>tr</code> 标签。</li>
<li><code>s.select('th/p/text()').extract()</code> 在之前的选择基础上继续对其子标签做选择，
这里就确实得选择到了分店名。<code>extract()</code> 则将该标签的文本数据读取出来。</li>
<li><code>HtmlXPathSelector</code> 还有正则表达式接口，后文会提到。</li>
</ul>


<h3>Field, Item 及 Item Loader</h3>

<p>Field 仅仅是一个 <code>dict</code> 的 wrapper 类，因此使用方法与 <code>dict</code> 完全一样，在
scrapy 中它负责声明单个 Item 的字段及该字段的各种行为（如序列化方法
<code>serializer</code>）。</p>

<p>Item 用 Field 定义了单个有效数据的具体字段，而实际中则是主要有两种方法写入
数据：</p>

<ol>
<li>使用其类似 <code>dict</code> 的接口进行数据的写入和读取，<code>key</code> 为字段名。</li>
<li>使用 <a href="http://doc.scrapy.org/en/0.14/topics/loaders.html">Item Loader</a>。</li>
</ol>


<p><code>dict</code> 接口的用法如上所示很简单，这里说一下 Item Loader。</p>

<div class="highlight"><pre><code class="python"><span class="kn">from</span> <span class="nn">scrapy.contrib.loader</span> <span class="kn">import</span> <span class="n">ItemLoader</span>
<span class="kn">from</span> <span class="nn">scrapy.contrib.loader.processor</span> <span class="kn">import</span> <span class="n">Compose</span>

<span class="kn">from</span> <span class="nn">lawson.items</span> <span class="kn">import</span> <span class="n">ConvStore</span>


<span class="k">class</span> <span class="nc">StoreLoader</span><span class="p">(</span><span class="n">ItemLoader</span><span class="p">):</span>
    <span class="n">default_output_processor</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">(</span><span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">unicode</span><span class="o">.</span><span class="n">strip</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">branch_in</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">yield</span> <span class="n">v</span> <span class="o">+</span> <span class="s">u&#39;店&#39;</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">v</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s">u&#39;店&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">v</span>


<span class="k">class</span> <span class="nc">LawsonSpider</span><span class="p">(</span><span class="n">CrawlSpider</span><span class="p">):</span>
    <span class="o">...</span>

    <span class="k">def</span> <span class="nf">parse_store_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">hxs</span> <span class="o">=</span> <span class="n">HtmlXPathSelector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="n">store_selectors</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;//div[@class=&quot;ShopList&quot;]/table/tr&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>

        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">store_selectors</span><span class="p">:</span>
            <span class="n">store</span> <span class="o">=</span> <span class="n">StoreLoader</span><span class="p">(</span><span class="n">item</span><span class="o">=</span><span class="n">ConvStore</span><span class="p">(),</span> <span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;name&#39;</span><span class="p">,</span> <span class="s">u&#39;罗森&#39;</span><span class="p">)</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;alias&#39;</span><span class="p">,</span> <span class="s">u&#39;Lawson&#39;</span><span class="p">)</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;branch&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;th/p/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">())</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;address&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;td/span/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">())</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;district&#39;</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s">&#39;link_text&#39;</span><span class="p">])</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;city&#39;</span><span class="p">,</span> <span class="s">u&#39;上海&#39;</span><span class="p">)</span>

            <span class="k">yield</span> <span class="n">store</span><span class="o">.</span><span class="n">load_item</span><span class="p">()</span>
</code></pre></div>


<p>Item Loader 的主要作用是对抓取数据的各个字段进行特殊处理，在这里我们定义了一个
<code>StoreLoader</code> 类继承（Inherit）自 <code>ItemLoader</code>：</p>

<ul>
<li><code>default_output_processor</code> 定义默认的输出处理器，这里我们对抓取的数据值进行
strip 操作。</li>
<li><code>branch_in</code> 方法是对 <code>branch</code> 字段的特殊处理，他发生在输入的时候，也就是刚抓
取到数据之后。这里的处理是为没有<code>店</code>这个字的分店名补上这个字。</li>
<li><code>&lt;field&gt;_in</code> 和 <code>&lt;field&gt;_out</code> 会各对指定字段做一次处理，前者是在刚抓取到数据
时，后者是在最终输出之前，用户根据需要定义相应方法。

<ul>
<li>scrapy 有一些 <a href="http://doc.scrapy.org/en/0.14/topics/loaders.html#module-scrapy.contrib.loader.processor">built-in processor</a>
可以直接使用，进行一些通用处理。</li>
</ul>
</li>
<li><code>add_value</code> 将值赋予相应字段，很好理解。</li>
<li><code>load_item</code> 返回该条填充过数据的 Item。</li>
</ul>


<p>使用 Item Loader 的好处显而易见，我们有一个统一的地方对所有数据字段进行处理，不
用将其混入抓取逻辑，使整个流程分工明确。</p>

<p>另一个常用的 Item Loader 是 <code>XPathItemLoader</code>，显然这个版本利用了 XPath：</p>

<div class="highlight"><pre><code class="python"><span class="n">store</span> <span class="o">=</span> <span class="n">XPathItemLoader</span><span class="p">(</span><span class="n">item</span><span class="o">=</span><span class="n">ConvStore</span><span class="p">(),</span> <span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
<span class="n">store</span><span class="o">.</span><span class="n">add_xpath</span><span class="p">(</span><span class="s">&#39;branch&#39;</span><span class="p">,</span> <span class="s">&#39;//div[@class=&quot;ShopList&quot;]/table/tr[2]/th/p/text()&#39;</span><span class="p">)</span>
</code></pre></div>


<p>它将字段与 XPath 表达式关联起来，直接完成定位、读取和写入数据的操作，很方便。</p>

<h3>加上经纬度</h3>

<p>经纬度对于定位一个地点是很有用的，通过电子地图能够精确地定位至相关地点。我发现
罗森网站提供了这个信息，但它并未明文显示，而是需要通过其所链接到的百度地图的页
面中去抓取下来，听起来很麻烦，但实际却很简单。</p>

<div class="highlight"><pre><code class="python"><span class="kn">from</span> <span class="nn">urlparse</span> <span class="kn">import</span> <span class="n">urljoin</span>

<span class="kn">from</span> <span class="nn">scrapy.contrib.loader</span> <span class="kn">import</span> <span class="n">XPathItemLoader</span>
<span class="kn">from</span> <span class="nn">scrapy.http</span> <span class="kn">import</span> <span class="n">Request</span>
<span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">HtmlXPathSelector</span>
<span class="kn">from</span> <span class="nn">scrapy.utils.response</span> <span class="kn">import</span> <span class="n">get_base_url</span>

<span class="kn">from</span> <span class="nn">poi_scrape.items</span> <span class="kn">import</span> <span class="n">ConvStore</span>


<span class="k">class</span> <span class="nc">StoreLoader</span><span class="p">(</span><span class="n">XPathItemLoader</span><span class="p">):</span>
    <span class="o">...</span>


<span class="k">class</span> <span class="nc">LawsonSpider</span><span class="p">(</span><span class="n">BasePoiSpider</span><span class="p">):</span>
    <span class="o">...</span>

    <span class="k">def</span> <span class="nf">parse_geo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">hxs</span> <span class="o">=</span> <span class="n">HtmlXPathSelector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="n">store</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s">&#39;store&#39;</span><span class="p">]</span>

        <span class="n">lng</span><span class="p">,</span> <span class="n">lat</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">re</span><span class="p">(</span><span class="s">r&#39;(\d+\.\d+),(\d+\.\d+)&#39;</span><span class="p">)</span>
        <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;latitude&#39;</span><span class="p">,</span> <span class="n">lat</span><span class="p">)</span>
        <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;longitude&#39;</span><span class="p">,</span> <span class="n">lng</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">store</span><span class="o">.</span><span class="n">load_item</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">parse_store_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="o">...</span>

        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">store_selectors</span><span class="p">:</span>
            <span class="n">store</span> <span class="o">=</span> <span class="n">StoreLoader</span><span class="p">(</span><span class="n">item</span><span class="o">=</span><span class="n">ConvStore</span><span class="p">(),</span> <span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
            <span class="o">...</span>

            <span class="n">map_rel_url</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;td/a/@rel&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">map_rel_url</span><span class="p">:</span>
                <span class="n">map_url</span> <span class="o">=</span> <span class="n">urljoin</span><span class="p">(</span><span class="n">get_base_url</span><span class="p">(</span><span class="n">response</span><span class="p">),</span> <span class="n">map_rel_url</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">req</span> <span class="o">=</span> <span class="n">Request</span><span class="p">(</span><span class="n">map_url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse_geo</span><span class="p">)</span>
                <span class="n">req</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s">&#39;store&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">store</span>
                <span class="k">yield</span> <span class="n">req</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">yield</span> <span class="n">store</span><span class="o">.</span><span class="n">load_item</span><span class="p">()</span>
</code></pre></div>


<p>这里为 <code>LawsonSpider</code> 新增了一个方法 <code>parse_geo</code>，同时改写了
<code>parse_store_list</code>。</p>

<ul>
<li>在 <code>parse_store_list</code> 的循环中我抓取每个店的 <code>tr</code> 标签中的 <code>td/a/@rel</code> 属性
（Attribute）（这里 <code>@rel</code> 表示 <code>a</code> 标签的 <code>rel</code> 属性），若有这一属性则对这个
地图的链接发起请求，即 <code>yield req</code>。

<ul>
<li>在 scrapy 中，spider 类中的方法若返回 Request 实例则 scrapy 会自动对该
Request 包含的 URL 发出请求，并将其返回的结果封装为 Response 后交给
<code>callback</code> 参数中指定的方法处理，若未指定 <code>callback</code>，则交给 <code>parse</code> 方法处
理。</li>
</ul>
</li>
<li><code>req.meta['store'] = store</code>，每个 Request 有一个预定义的 <code>meta</code> 属性（<code>dict</code>
），保存在其中的值在其对应的 Response 中可以再次取出：
<code>store = response.meta['store']</code>。</li>
<li><code>hxs.re(r'(\d+\.\d+),(\d+\.\d+)')</code> 使用了 <code>HtmlXPathSelector</code> 的正则表达式接
口直接从网页中通过正则表达式匹配抓取数据。</li>
</ul>


<h3>完整 spider 代码</h3>

<p><code>items.py</code> 没有改动，与上文中的一致。</p>

<div class="highlight"><pre><code class="python"><span class="c"># vim: fileencoding=utf-8</span>
<span class="kn">from</span> <span class="nn">urlparse</span> <span class="kn">import</span> <span class="n">urljoin</span>

<span class="kn">from</span> <span class="nn">scrapy.contrib.linkextractors.sgml</span> <span class="kn">import</span> <span class="n">SgmlLinkExtractor</span>
<span class="kn">from</span> <span class="nn">scrapy.contrib.loader</span> <span class="kn">import</span> <span class="n">XPathItemLoader</span>
<span class="kn">from</span> <span class="nn">scrapy.contrib.loader.processor</span> <span class="kn">import</span> <span class="n">Compose</span>
<span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">CrawlSpider</span><span class="p">,</span> <span class="n">Rule</span>
<span class="kn">from</span> <span class="nn">scrapy.http</span> <span class="kn">import</span> <span class="n">Request</span>
<span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">HtmlXPathSelector</span>
<span class="kn">from</span> <span class="nn">scrapy.utils.response</span> <span class="kn">import</span> <span class="n">get_base_url</span>

<span class="kn">from</span> <span class="nn">lawson.items</span> <span class="kn">import</span> <span class="n">ConvStore</span>


<span class="k">class</span> <span class="nc">StoreLoader</span><span class="p">(</span><span class="n">XPathItemLoader</span><span class="p">):</span>
    <span class="n">default_output_processor</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">(</span><span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">unicode</span><span class="o">.</span><span class="n">strip</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">branch_in</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">yield</span> <span class="n">v</span> <span class="o">+</span> <span class="s">u&#39;店&#39;</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">v</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s">u&#39;店&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">v</span>


<span class="k">class</span> <span class="nc">LawsonSpider</span><span class="p">(</span><span class="n">CrawlSpider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&#39;lawson&#39;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.lawson.com.cn/shops&#39;</span><span class="p">]</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;lawson.com.cn&#39;</span><span class="p">]</span>
    <span class="n">rules</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">Rule</span><span class="p">(</span><span class="n">SgmlLinkExtractor</span><span class="p">(</span><span class="n">allow</span><span class="o">=</span><span class="s">r&#39;list\?area_id=\d+&#39;</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="s">&#39;a&#39;</span><span class="p">),</span>
                <span class="n">callback</span><span class="o">=</span><span class="s">&#39;parse_store_list&#39;</span><span class="p">),</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse_geo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">hxs</span> <span class="o">=</span> <span class="n">HtmlXPathSelector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="n">store</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s">&#39;store&#39;</span><span class="p">]</span>

        <span class="n">lng</span><span class="p">,</span> <span class="n">lat</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">re</span><span class="p">(</span><span class="s">r&#39;(\d+\.\d+),(\d+\.\d+)&#39;</span><span class="p">)</span>
        <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;latitude&#39;</span><span class="p">,</span> <span class="n">lat</span><span class="p">)</span>
        <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;longitude&#39;</span><span class="p">,</span> <span class="n">lng</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">store</span><span class="o">.</span><span class="n">load_item</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">parse_store_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">hxs</span> <span class="o">=</span> <span class="n">HtmlXPathSelector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="n">store_selectors</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;//div[@class=&quot;ShopList&quot;]/table/tr&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>

        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">store_selectors</span><span class="p">:</span>
            <span class="n">store</span> <span class="o">=</span> <span class="n">StoreLoader</span><span class="p">(</span><span class="n">item</span><span class="o">=</span><span class="n">ConvStore</span><span class="p">(),</span> <span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;name&#39;</span><span class="p">,</span> <span class="s">u&#39;罗森&#39;</span><span class="p">)</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;alias&#39;</span><span class="p">,</span> <span class="s">u&#39;Lawson&#39;</span><span class="p">)</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;branch&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;th/p/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">())</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;address&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;td/span/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">())</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;district&#39;</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s">&#39;link_text&#39;</span><span class="p">])</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;city&#39;</span><span class="p">,</span> <span class="s">u&#39;上海&#39;</span><span class="p">)</span>

            <span class="n">map_rel_url</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;td/a/@rel&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">map_rel_url</span><span class="p">:</span>
                <span class="n">map_url</span> <span class="o">=</span> <span class="n">urljoin</span><span class="p">(</span><span class="n">get_base_url</span><span class="p">(</span><span class="n">response</span><span class="p">),</span> <span class="n">map_rel_url</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">req</span> <span class="o">=</span> <span class="n">Request</span><span class="p">(</span><span class="n">map_url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse_geo</span><span class="p">)</span>
                <span class="n">req</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s">&#39;store&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">store</span>
                <span class="k">yield</span> <span class="n">req</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">yield</span> <span class="n">store</span><span class="o">.</span><span class="n">load_item</span><span class="p">()</span>
</code></pre></div>


<h3>scrapy 命令行工具</h3>

<p>scrapy 提供了一些命令行工具
（<a href="http://doc.scrapy.org/en/0.14/topics/commands.html">Command line tool</a>），之
前创建 Project 的时候用到的 <code>startproject</code> 就是其中之一。而除了这个之外，其他工
具也各自提供了相当有用的功能。</p>

<div class="highlight"><pre><code class="text">$ scrapy
Scrapy 0.14.4 - project: lawson

Usage:
  scrapy &lt;command&gt; [options] [args]

Available commands:
  crawl         Start crawling from a spider or URL
  deploy        Deploy project in Scrapyd target
  edit          Edit spider
  fetch         Fetch a URL using the Scrapy downloader
  genspider     Generate new spider using pre-defined templates
  list          List available spiders
  parse         Parse URL (using its spider) and print the results
  runspider     Run a self-contained spider (without creating a project)
  server        Start Scrapyd server for this project
  settings      Get settings values
  shell         Interactive scraping console
  startproject  Create new project
  version       Print Scrapy version
  view          Open URL in browser, as seen by Scrapy

Use &quot;scrapy &lt;command&gt; -h&quot; to see more info about a command
</code></pre></div>


<p>这里仅挑出部分来讲。</p>

<h4><code>shell</code></h4>

<div class="highlight"><pre><code class="sh"><span class="nv">$ </span>scrapy shell <span class="s1">&#39;http://www.lawson.com.cn/shops&#39;</span>
</code></pre></div>


<p>运行后会进入 Python Interpreter，在这里我们能进行各种试验，配合
<a href="http://doc.scrapy.org/en/0.14/topics/firebug.html">Firebug</a> 之类的工具，为程序
构建一个原型：</p>

<ul>
<li>抓取各区分店列表链接，同时演示 <code>SgmlLInkExtractor</code> 用法：</li>
</ul>


<div class="highlight"><pre><code class="python"><span class="n">In</span> <span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="kn">from</span> <span class="nn">scrapy.contrib.linkextractors.sgml</span> <span class="kn">import</span> <span class="n">SgmlLinkExtractor</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">SgmlLinkExtractor</span><span class="p">(</span><span class="n">allow</span><span class="o">=</span><span class="s">r&#39;list\?area_id=\d+&#39;</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="s">&#39;a&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_links</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
<span class="p">[</span><span class="n">Link</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="s">&#39;http://www.lawson.com.cn/shops/list?area_id=1&#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s">u&#39;</span><span class="se">\u957f\u5b81\u533a</span><span class="s">&#39;</span><span class="p">,</span> <span class="n">fragment</span><span class="o">=</span><span class="s">&#39;&#39;</span><span class="p">,</span> <span class="n">nofollow</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
 <span class="n">Link</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="s">&#39;http://www.lawson.com.cn/shops/list?area_id=2&#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s">u&#39;</span><span class="se">\u5f90\u6c47\u533a</span><span class="s">&#39;</span><span class="p">,</span> <span class="n">fragment</span><span class="o">=</span><span class="s">&#39;&#39;</span><span class="p">,</span> <span class="n">nofollow</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
 <span class="n">Link</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="s">&#39;http://www.lawson.com.cn/shops/list?area_id=3&#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s">u&#39;</span><span class="se">\u9759\u5b89\u533a</span><span class="s">&#39;</span><span class="p">,</span> <span class="n">fragment</span><span class="o">=</span><span class="s">&#39;&#39;</span><span class="p">,</span> <span class="n">nofollow</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
 <span class="o">...</span>
</code></pre></div>


<ul>
<li>抓取分店列表，<code>fetch</code> 用来载入新的 URL：</li>
</ul>


<div class="highlight"><pre><code class="python"><span class="n">In</span> <span class="p">[</span><span class="mi">6</span><span class="p">]:</span> <span class="n">fetch</span><span class="p">(</span><span class="s">&#39;http://www.lawson.com.cn/shops/list?area_id=1&#39;</span><span class="p">)</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">7</span><span class="p">]:</span> <span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;//div[@class=&quot;ShopList&quot;]/table/tr&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">7</span><span class="p">]:</span>
<span class="p">[</span><span class="o">&lt;</span><span class="n">HtmlXPathSelector</span> <span class="n">xpath</span><span class="o">=</span><span class="s">&#39;//div[@class=&quot;ShopList&quot;]/table/tr&#39;</span> <span class="n">data</span><span class="o">=</span><span class="s">u&#39;&lt;tr&gt;&lt;th scope=&quot;row&quot; class=&quot;linetop&quot;&gt;</span><span class="se">\n\t\t\t</span><span class="s">&#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="n">HtmlXPathSelector</span> <span class="n">xpath</span><span class="o">=</span><span class="s">&#39;//div[@class=&quot;ShopList&quot;]/table/tr&#39;</span> <span class="n">data</span><span class="o">=</span><span class="s">u&#39;&lt;tr&gt;&lt;th scope=&quot;row&quot; class=&quot;linetop&quot;&gt;</span><span class="se">\n\t\t\t</span><span class="s">&#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="n">HtmlXPathSelector</span> <span class="n">xpath</span><span class="o">=</span><span class="s">&#39;//div[@class=&quot;ShopList&quot;]/table/tr&#39;</span> <span class="n">data</span><span class="o">=</span><span class="s">u&#39;&lt;tr&gt;&lt;th scope=&quot;row&quot; class=&quot;linetop&quot;&gt;</span><span class="se">\n\t\t\t</span><span class="s">&#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">...</span><span class="p">]</span>
</code></pre></div>


<ul>
<li>抓取分店名称，演示 <code>HtmlXPathSelector</code> 用法：</li>
</ul>


<div class="highlight"><pre><code class="python"><span class="n">In</span> <span class="p">[</span><span class="mi">8</span><span class="p">]:</span> <span class="n">s</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;//div[@class=&quot;ShopList&quot;]/table/tr&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:][</span><span class="mi">0</span><span class="p">]</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">9</span><span class="p">]:</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;th/p/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">9</span><span class="p">]:</span> <span class="p">[</span><span class="s">u&#39;</span><span class="se">\n\t\t\t\t\u53e4\u5317\u65b0\u533a\n\t\t\t\t</span><span class="s">&#39;</span><span class="p">]</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">11</span><span class="p">]:</span> <span class="k">print</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;th/p/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">+</span> <span class="s">u&#39;店&#39;</span>
<span class="err">古北新区店</span>
</code></pre></div>


<p>这是一个相当完善的命令行界面，提供了所有必需的网页分析及抓取工具，十分适合在实
际写抓取程序前做实验。</p>

<p>而 <code>shell</code> 不仅能从命令行直接调用，还能从程序中调用直接进入以便分析程序做调试：</p>

<div class="highlight"><pre><code class="python"><span class="kn">from</span> <span class="nn">scrapy.shell</span> <span class="kn">import</span> <span class="n">inspect_response</span>


<span class="k">class</span> <span class="nc">LawsonSpider</span><span class="p">(</span><span class="n">BasePoiSpider</span><span class="p">):</span>
    <span class="o">...</span>

    <span class="k">def</span> <span class="nf">parse_geo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">inspect_response</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse_store_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="o">...</span>
</code></pre></div>


<p>这样在执行到 <code>parse_geo</code> 时就会掉入 <code>shell</code> 界面，可以做进一步调试。</p>

<h4><code>crawl</code></h4>

<p>真正的抓取就是通过这个命令执行的：</p>

<div class="highlight"><pre><code class="sh"><span class="nv">$ </span>scrapy crawl lawson
</code></pre></div>




<div class="highlight"><pre><code class="text">2012-07-18 15:14:58+0800 [scrapy] INFO: Scrapy 0.14.4 started (bot: lawson)
2012-07-18 15:14:58+0800 [scrapy] DEBUG: Enabled extensions: FeedExporter, LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2012-07-18 15:14:58+0800 [scrapy] DEBUG: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, RedirectMiddleware, CookiesMiddleware, HttpCompressionMiddleware, ChunkedTransferMiddleware, DownloaderStats
2012-07-18 15:14:58+0800 [scrapy] DEBUG: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2012-07-18 15:14:58+0800 [scrapy] DEBUG: Enabled item pipelines:
2012-07-18 15:14:58+0800 [lawson] INFO: Spider opened
2012-07-18 15:14:58+0800 [lawson] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2012-07-18 15:14:58+0800 [scrapy] DEBUG: Telnet console listening on 0.0.0.0:6023
2012-07-18 15:14:58+0800 [scrapy] DEBUG: Web service listening on 0.0.0.0:6080
2012-07-18 15:14:59+0800 [lawson] DEBUG: Crawled (200) &lt;GET http://www.lawson.com.cn/shops&gt; (referer: None)
2012-07-18 15:14:59+0800 [lawson] DEBUG: Crawled (200) &lt;GET http://www.lawson.com.cn/shops/list?area_id=16&gt; (referer: http://www.lawson.com.cn/shops)
2012-07-18 15:14:59+0800 [lawson] DEBUG: Scraped from &lt;200 http://www.lawson.com.cn/shops/list?area_id=16&gt;
    {&#39;address&#39;: u&#39;\u5609\u5b9a\u533a\u5609\u677e\u516c\u8def6128\u53f7&#39;,
     &#39;alias&#39;: u&#39;Lawson&#39;,
     &#39;branch&#39;: u&#39;\u540c\u6d4e\u5927\u5b66\u5e97&#39;,
     &#39;city&#39;: u&#39;\u4e0a\u6d77&#39;,
     &#39;district&#39;: u&#39;\u5609\u5b9a\u533a&#39;,
     &#39;name&#39;: u&#39;\u7f57\u68ee&#39;}
...
2012-07-18 15:15:01+0800 [lawson] DEBUG: Crawled (200) &lt;GET http://www.lawson.com.cn/shops/199/map&gt; (referer: http://www.lawson.com.cn/shops/list?area_id=12)
2012-07-18 15:15:01+0800 [lawson] DEBUG: Scraped from &lt;200 http://www.lawson.com.cn/shops/199/map&gt;
    {&#39;address&#39;: u&#39;\u677e\u6c5f\u533a\u897f\u6797\u5317\u8def1048\u53f7&#39;,
     &#39;alias&#39;: u&#39;Lawson&#39;,
     &#39;branch&#39;: u&#39;\u677e\u6c5f\u5987\u5e7c\u4fdd\u5065\u9662\u5e97&#39;,
     &#39;city&#39;: u&#39;\u4e0a\u6d77&#39;,
     &#39;district&#39;: u&#39;\u677e\u6c5f\u533a&#39;,
     &#39;latitude&#39;: u&#39;31.030622&#39;,
     &#39;longitude&#39;: u&#39;121.225586&#39;,
     &#39;name&#39;: u&#39;\u7f57\u68ee&#39;}
...
2012-07-18 15:15:21+0800 [lawson] INFO: Closing spider (finished)
2012-07-18 15:15:21+0800 [lawson] INFO: Stored csv feed (320 items) in: lawson_store.csv
2012-07-18 15:15:21+0800 [lawson] INFO: Dumping spider stats:
    {&#39;downloader/request_bytes&#39;: 158946,
     &#39;downloader/request_count&#39;: 309,
     &#39;downloader/request_method_count/GET&#39;: 309,
     &#39;downloader/response_bytes&#39;: 1883104,
     &#39;downloader/response_count&#39;: 309,
     &#39;downloader/response_status_count/200&#39;: 309,
     &#39;finish_reason&#39;: &#39;finished&#39;,
     &#39;finish_time&#39;: datetime.datetime(2012, 7, 18, 7, 15, 21, 905140),
     &#39;item_scraped_count&#39;: 320,
     &#39;request_depth_max&#39;: 2,
     &#39;scheduler/memory_enqueued&#39;: 309,
     &#39;start_time&#39;: datetime.datetime(2012, 7, 18, 7, 14, 58, 538838)}
2012-07-18 15:15:21+0800 [lawson] INFO: Spider closed (finished)
2012-07-18 15:15:21+0800 [scrapy] INFO: Dumping global stats:
    {}
</code></pre></div>


<p>从最后的报告中可以看到这个 spider 在一分钟内抓取了该网站全部320条数据
（<code>item_scraped_count</code>）。</p>

<p>若要输出抓取结果到一个文件，则加上参数：</p>

<div class="highlight"><pre><code class="sh">scrapy crawl lawson -o store.csv -t csv
</code></pre></div>


<p>这样，这篇 scrapy 使用教程的第一部分就结束了。</p>

  </section>
</article>


<section class="comments well">
  <div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'kdblue'; // required: replace example with your forum shortname
    var disqus_identifier = 'http://kanedou.me/2012/07/introducing-python-scrapy-part-i/';
    var disqus_url = 'http://kanedou.me/2012/07/introducing-python-scrapy-part-i/';
    var disqus_script = 'embed.js';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

</section>



      </div>
      <footer role="contentinfo" class="contentinfo">
        <div>
  
  
  <span class="copy">&copy; 2004-2013 kane</span>
  |
  <span class="license">
    <a href="http://creativecommons.org/licenses/by/3.0/cn/">license</a>
  </span>
  |
  <span class="engine">
    powered by <a href="http://jekyllrb.com/">jekyll</a> & <a href="http://compass-style.org">compass</a>
  </span>
</div>

      </footer>
    </div>
  </body>
</html>
