<!DOCTYPE html>
<html lang="zh">
  <head>
    <meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html" />
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="author" content="Kane Dou">
<link rel="shortcut icon" href="/favicon.ico">
<link href="/feed.xml" rel="alternate" title="kandou.me" type="application/rss+xml">
<link rel="stylesheet" href="/assets/stylesheets/screen.css" />
<link rel="stylesheet" href="/assets/stylesheets/syntax.css" />
<title>
  kanedou.me
</title>

  </head>
  <body>
    <div class="container">
      <header id="masthead">
        <div class="row">
          <div class="branding">
            <h1>
              <a href="/">kanedou.me</a>
            </h1>
          </div>
          <div class="span4 navigation">
            <nav role="navigation">
  <ul class="nav nav-pills">
    <li><a href="/archive.html"><span>archive</span></a></li>
    <li><a href="/links.html"><span>links</span></a></li>
    <li><a href="/about.html"><span>about</span></a></li>
    <li><a href="/feed.xml"><span>feed</span></a></li>
  </ul>
</nav>

          </div>
        </div>
      </header>
      <div id="content">
        <div class="blog-index">
  
  
  
  
<article role="article" class="well">
  <header>
    <section class="title">
      <h1>
        
        <a href="/2013/05/hills-like-white-elephants/">Hills Like White Elephants</a>
        
      </h1>
    </section>
    <section class="meta">
      @<time>2013-05-13</time>
      <span class="categories">
        
        <em class="category">#fiction</em>
        
        <em class="category">#literature</em>
        
      </span>
    </section>
  </header>
  <section class="post serif">
    <p>By <em>Ernest Hemingway</em></p>

<p>The hills across the valley of the Ebro were long and white. On this side there
was no shade and no trees and the station was between two lines of rails in the
sun. Close against the side of the station there was the warm shadow of the
building and a curtain, made of strings of bamboo beads, hung across the open
door into the bar, to keep out flies. The American and the girl with him sat at
a table in the shade, outside the building. It was very hot and the express
from Barcelona would come in forty minutes. It stopped at this junction for two
minutes and went to Madrid.</p>

<p>"What should we drink?" the girl asked. She had taken off her hat and put on
the table.<br />
"It's pretty hot," the man said.<br />
"Let's drink beer."<br />
"Dos cervezas," the man said into the curtain.<br />
"Big ones?" a woman asked from the doorway.<br />
"Yes. Two big ones."</p>

<p>The woman brought two glasses of beer and two felt pads. She put the felt pads
and the beer glass on the table and looked at the man and the girl. The girl
was looking off at the line of hills. They were white in the sun and the
country was brown and dry.</p>

<p>"They look like white elephants," she said.<br />
"I've never seen one," the man drank his beer.<br />
"No, you wouldn't have."<br />
"I might have," the man said. "Just because you say I wouldn't have doesn"t
prove anything."<br />
The girl looked at the bead curtain. "They've painted something on it," she
said. "What does it say?"<br />
"Anis del Toro. It's a drink."<br />
"Could we try it?"<br />
The man called "Listen" through the curtain. The woman came out from the bar.
"Four reales." "We want two Anis del Toro."<br />
"With water?"<br />
"Do you want it with water?"<br />
"I don't know," the girl said. "Is it good with water?"<br />
"It's all right."<br />
"You want them with water?" asked the woman.<br />
"Yes, with water."<br />
"it tastes like liquorice," the girl said and put the glass down.<br />
"That's the way with everything."<br />
"Yes," said the girl. "Everything tastes of liquorice. Especially all the
things you've waited so long for, like absinthe."<br />
"Oh, cut it out."<br />
"You started it," the girl said. "I was being amused. I was having a fine
time."<br />
"Well, let's try and have a fine time."<br />
"All right,. I was trying. I said the mountains looked like white elephants.
Wasn't that bright?"<br />
"That was bright."<br />
"I wanted to try this new drink. That's all we do, isn't it -- look at things
and try new drinks?"<br />
"I guess so."<br />
The girl looked across at the hills.<br />
"They're lovely hills," she said. "They don't really look like white elephants.
I just meant the colouring of their skin through the trees."<br />
"Should we have another drink?"<br />
"All right."<br />
The warm wind blew the bead curtain against the table.</p>

<p>"The beer's nice and cool," the man said.<br />
"It's lovely," the girl said.<br />
"It's really an awfully simple operation, Jig," the man said. "It's not really
an operation at all."<br />
The girl looked at the ground the table legs rested on.<br />
"I know you wouldn't mind it, Jig. It's really not anything. It's just to let
the air in."<br />
The girl did not say anything.<br />
"I'll go with you and I'll stay with you all the time. They just let the air in
and then it's all perfectly natural."<br />
"Then what will we do afterwards?"<br />
"We'll be fine afterwards. Just like we were before."<br />
"What makes ou think so?"<br />
"That's the only thing that bothers us. It's the only thing that's made us
unhappy."<br />
The girl looked at the bead curtain, put her hand out and took hold of two of
the strings of beads.<br />
"And you think then we'll be all right and be happy."<br />
"I know we will. You don't have to be afraid. I've known lots of people that
have done it."<br />
"So have I," said the girl. "And afterwards they were all so happy."<br />
"Well," the man said, "if you don't want to you don't have to. I wouldn't have
you do it if you didn't want to. But I know it's perfectly simple."<br />
"And you really want to?"<br />
"I think it's the best thing to do. But I don't want you to do it if you don't
really want to."<br />
"And if I do it you'll be happy and things will be like they were and you'll
love me?"<br />
"I love you now. You know I love you."<br />
"I know. But if I do it, then it will be nice again if I say things are like
white elephants, and you'll like it?"<br />
"I'll love it. I love it now but I just can't think about it. You know how I
get when I worry."<br />
"If I do it you won't ever worry?"<br />
"I won't worry about that because it's perfectly simple."<br />
"Then I'll do it. Because I don't care about me."<br />
"What do you mean?"<br />
"I don't care about me."<br />
"Well, I care about you."<br />
"Oh, yes. But I don't care about me. And I'll do it and then everything will be
fine."<br />
"I don't want you to do it if you feel that way."<br /></p>

<p>The girl stood up and walked to the end of the station. Across, on the other
side, were fields of grain and trees along the banks of the Ebro. Far away,
beyond the river, were mountains. The shadow of a cloud moved across the field
of grain and she saw the river through the trees.</p>

<p>"And we could have all this," she said. "And we could have everything and every
day we make it more impossible."<br />
"What did you say?"<br />
"I said we could have everything."<br />
"We can have everything."<br />
"No, we can't."<br />
"We can have the whole world."<br />
"No, we can't."<br />
"We can go everywhere."<br />
"No, we can't. It isn't ours any more."<br />
"It's ours."<br />
"No, it isn't. And once they take it away, you never get it back."<br />
"But they haven't taken it away."<br />
"We'll wait and see."<br />
"Come on back in the shade," he said. "You mustn't fell that way."<br />
"I don't feel any way," the girl said. "I just know things."<br />
"I don't want you to do anything that you don't want to do -"<br />
"Nor that isn't good for me," she said. "I know. Could we have another
beer?"<br />
"All right. But you've got to realize -- "<br />
"I realize," the girl said. "Can't we may be stop talking?"<br />
They sat down at the table and the girl looked across at the hills on the dry
side of the valley and the man looked at her and at the table.</p>

<p>"You've got to realize," he said, "that I don't want you to do it if you don't
want to. I'm perfectly willing to go through with it if it means anything to
you."<br />
"Doesn't it mean anything to you? We could get along."<br />
"Of course it does. But I don't want anybody but you. I don't want anyone else.
And I know it's perfectly simple."<br />
"Yes, you know it's perfectly simple."<br />
"It's all right for you to say that, but I do know it."<br />
"Would you do something for me now?"<br />
"I'd do anything for you."<br />
"Would you please please please please please please please stop
talking?"<br />
He did not say anything but looked at the bags against the wall of the
station.<br />
There were labels on them from all the hotels where they had spentl
nights.<br />
"But I don't want you to," he said, "I don't care anything about it."<br />
"I'll scream," the girl said.<br />
The woman came out through the curtains with two glasses of beer and put them
down on the damp felt pads. "The train comes in five minutes," she said.<br />
"What did she say?" asked the girl.<br />
"That the train is coming in five minutes."<br />
The girl smiled brightly at the woman, to thank her.<br />
"I'd better take the bags over to the other side of the station," the man
said.<br />
She smiled at him. "All right. Then come back and we'll finish the beer."</p>

<p>He picked up the two heavy bags and carried them around the station to the
other tracks. He looked up the tracks but could not see the train. Coming back,
he walked through the bar-room, where people waiting for the train were
drinking. He drank an Anis at the bar and looked at the people. They were all
waiting reasonably for the train. He went out through the bead curtain. She was
sitting at the table and smiled at him.</p>

<p>"Do you feel better?" he asked.<br />
"I feel fine," she said. "There's nothing wrong with me. I feel fine."</p>

<hr />

<p>抄自：<a href="http://www.asdk12.org/staff/grenier_tom/HOMEWORK/208194_Hills_Like_White_Elephants.pdf">Hills Like White Elephants (pdf)</a></p>

<hr />

<p>『白象似的群山』所记述的是不调和的冲突，及谜一般的意识与情感的流动。每次读都会
有新的细节浮现出来是她的魅力，但这不是真正隐藏在文本中的细节，而是你自己的经历
的又一次重现。</p>

<p>为何她会看到群山似白象？<br />
“让空气进去，就这么简单。”<br />
“如果你觉得不好那就不要做。”<br />
“如果这对你而言有任何意义的话那就不要做。”<br />
“这对你就没有一点儿意义吗？”</p>

<p>虽然这些稀松平常的对话看似没有什么深意，但一旦把自己代入小说的情景中之后你会选
择靠向一边，这种下意识自然而然的选择总是与你当下的状况相关联。你可能忏悔，也可
能同情，或是愤怒，甚至不屑一顾，这都是人的感觉，因为人会移情，因此才有共鸣。而
让这种联系更进一步深入的就是这文字中太多太多省略了的背景交代，她无从来，也无从
去，她是细节的堆积，和不动声色中两人无力的撕扯，在一个空旷的车站，和一个褐黄、
燥热的国度。</p>

<p>都说含蓄的美是东方的特色，但这篇作品中海明威所表现出的克制与冷静却是实实在在厚
实有力的。这让我想到『断背山』，没有喧哗激烈的交锋，只是平静的言辞和一些笨拙的
行为就将整个叙事撑起。</p>

<p>她没法表现更多，感受更多，诉说更多，只是：</p>

<blockquote><p>"I don't feel any way," the girl said. "I just know things."</p></blockquote>

<p>故事也就到此为止了。</p>

<hr />

<p>See also:</p>

<ul>
<li><a href="http://blog.anguscroll.com/how-to-read-a-book/">How to Read a Book</a></li>
<li><a href="http://en.wikipedia.org/wiki/Hills_Like_White_Elephants">http://en.wikipedia.org/wiki/Hills_Like_White_Elephants</a></li>
</ul>


  </section>
</article>

  
  
  
<article role="article" class="well">
  <header>
    <section class="title">
      <h1>
        
        <a href="/2013/04/go-composition/">go composition</a>
        
      </h1>
    </section>
    <section class="meta">
      @<time>2013-04-14</time>
      <span class="categories">
        
        <em class="category">#programming</em>
        
        <em class="category">#go</em>
        
      </span>
    </section>
  </header>
  <section class="post">
    <p>go 没有 inheritance，只有基于 interface 的 composition，但它提供了类似继承的 embedding 来使这一过程尽可能简洁。这里就用具体示例来说一下如何做。</p>

<p>假设我需要两个图片 URL 生成器，它能根据 http 请求来源生成相应的图片 URL 集合，例如从 mobile 来的请求我为其生成 original, cover 两个 URL，而从 desktop 来的请求则生成 original, preview 和 thumbnail 三个 URL。</p>

<p>整理一下需求：首先是 original, cover, preview 及 thumbnail 这四个基础的实际生成 URL 的生成器，然后是 mobile 及 desktop 这两个构筑在前四者之上的抽象分类。</p>

<div class="highlight"><pre><code class="go"><span class="kd">type</span> <span class="nx">OriginalUrlBuilder</span> <span class="kd">interface</span> <span class="p">{</span>
    <span class="nx">OriginalUrl</span><span class="p">()</span> <span class="kt">string</span>
<span class="p">}</span>

<span class="kd">type</span> <span class="nx">CoverUrlBuilder</span> <span class="kd">interface</span> <span class="p">{</span>
    <span class="nx">CoverUrl</span><span class="p">()</span> <span class="kt">string</span>
<span class="p">}</span>

<span class="kd">type</span> <span class="nx">PreviewUrlBuilder</span> <span class="kd">interface</span> <span class="p">{</span>
    <span class="nx">PreviewUrl</span><span class="p">()</span> <span class="kt">string</span>
<span class="p">}</span>

<span class="kd">type</span> <span class="nx">ThumbnailUrlBuilder</span> <span class="kd">interface</span> <span class="p">{</span>
    <span class="nx">ThumbnailUrl</span><span class="p">()</span> <span class="kt">string</span>
<span class="p">}</span>
</code></pre></div>


<p>这里我们先声明了四种不同 URL 的 interface，这是为了之后的 composition 更方便。</p>

<div class="highlight"><pre><code class="go"><span class="kd">type</span> <span class="nx">OriginalUrlBuilder</span> <span class="kd">interface</span> <span class="p">{</span>
    <span class="nx">OriginalUrl</span><span class="p">()</span> <span class="kt">string</span>
<span class="p">}</span>

<span class="kd">type</span> <span class="nx">Original</span> <span class="kd">struct</span> <span class="p">{</span>
    <span class="nx">image</span> <span class="o">*</span><span class="nx">models</span><span class="p">.</span><span class="nx">Image</span>  <span class="c1">// a model, the source we use to generate the URL, just a stab to complete the logic, pay no attention to it.</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="p">(</span><span class="nx">o</span> <span class="nx">Original</span><span class="p">)</span> <span class="nx">OriginalUrl</span><span class="p">()</span> <span class="kt">string</span> <span class="p">{</span><span class="c1">// generate original URL}</span>

<span class="kd">type</span> <span class="nx">CoverUrlBuilder</span> <span class="kd">interface</span> <span class="p">{</span>
    <span class="nx">CoverUrl</span><span class="p">()</span> <span class="kt">string</span>
<span class="p">}</span>

<span class="kd">type</span> <span class="nx">Cover</span> <span class="kd">struct</span> <span class="p">{</span>
    <span class="nx">image</span> <span class="o">*</span><span class="nx">models</span><span class="p">.</span><span class="nx">Image</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="p">(</span><span class="nx">c</span> <span class="nx">Cover</span><span class="p">)</span> <span class="nx">CoverUrl</span><span class="p">()</span> <span class="kt">string</span> <span class="p">{</span><span class="c1">// generate cover URL}</span>

<span class="kd">type</span> <span class="nx">PreviewUrlBuilder</span> <span class="kd">interface</span> <span class="p">{</span>
    <span class="nx">PreviewUrl</span><span class="p">()</span> <span class="kt">string</span>
<span class="p">}</span>

<span class="kd">type</span> <span class="nx">Preview</span> <span class="kd">struct</span> <span class="p">{</span>
    <span class="nx">image</span> <span class="o">*</span><span class="nx">models</span><span class="p">.</span><span class="nx">Image</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="p">(</span><span class="nx">p</span> <span class="nx">Preview</span><span class="p">)</span> <span class="nx">PreviewUrl</span><span class="p">()</span> <span class="kt">string</span> <span class="p">{</span><span class="c1">// generate preview URL}</span>

<span class="kd">type</span> <span class="nx">ThumbnailUrlBuilder</span> <span class="kd">interface</span> <span class="p">{</span>
    <span class="nx">ThumbnailUrl</span><span class="p">()</span> <span class="kt">string</span>
<span class="p">}</span>

<span class="kd">type</span> <span class="nx">Thumbnail</span> <span class="kd">struct</span> <span class="p">{</span>
    <span class="nx">image</span> <span class="o">*</span><span class="nx">models</span><span class="p">.</span><span class="nx">Image</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="p">(</span><span class="nx">t</span> <span class="nx">Thumbnail</span><span class="p">)</span> <span class="nx">ThumbnailUrl</span><span class="p">()</span> <span class="kt">string</span> <span class="p">{</span><span class="c1">// generate thumbnail URL}</span>
</code></pre></div>


<p>声明各个具体的 builder 并实现 interface。接下来是两个分类。</p>

<div class="highlight"><pre><code class="go"><span class="kd">type</span> <span class="nx">Desktop</span> <span class="kd">struct</span> <span class="p">{</span>
    <span class="o">*</span><span class="nx">Original</span>
    <span class="o">*</span><span class="nx">Preview</span>
    <span class="o">*</span><span class="nx">Thumbnail</span>
<span class="p">}</span>

<span class="kd">type</span> <span class="nx">Mobile</span> <span class="kd">struct</span> <span class="p">{</span>
    <span class="o">*</span><span class="nx">Original</span>
    <span class="o">*</span><span class="nx">Cover</span>
<span class="p">}</span>
</code></pre></div>


<p>这里的实现使用了 struct embedding，这里内嵌了基础 builder 的 pointer，效果是直接将内嵌 struct 的所有 method 带入新声明的 struct。这里有几点需要注意：</p>

<ul>
<li>内嵌的 struct 需要 initialize</li>
<li>在所声明 struct 上调用内嵌 struct 的 method 时其 receiver 为内嵌的 struct 而非其自身：</li>
</ul>


<div class="highlight"><pre><code class="go"><span class="c1">// when we call embedded method directly on the outer struct</span>
<span class="nx">d</span><span class="p">.</span><span class="nx">CoverUrl</span><span class="p">()</span>
<span class="c1">// it&#39;s exactly like first defining this book-keeping method on the outer struct and then calling it</span>
<span class="kd">func</span> <span class="p">(</span><span class="nx">d</span> <span class="nx">Desktop</span><span class="p">)</span> <span class="nx">CoverUrl</span><span class="p">()</span> <span class="kt">string</span> <span class="p">{</span>
    <span class="nx">d</span><span class="p">.</span><span class="nx">Cover</span><span class="p">.</span><span class="nx">CoverUrl</span><span class="p">()</span>  <span class="c1">// receiver is `Cover&#39; not `Desktop&#39;</span>
<span class="p">}</span>
<span class="nx">d</span><span class="p">.</span><span class="nx">CoverUrl</span><span class="p">()</span>
</code></pre></div>


<ul>
<li>内嵌 struct 的 field name 为其 unqualified name，即去除 package name 后的部分。</li>
<li><a href="http://golang.org/doc/effective_go.html#embedding">http://golang.org/doc/effective_go.html#embedding</a></li>
</ul>


<p>之后看一下如何实际使用这些 URL builder。</p>

<div class="highlight"><pre><code class="go"><span class="kd">func</span> <span class="nx">GetUrlBuilder</span><span class="p">(</span><span class="nx">reqType</span> <span class="kt">string</span><span class="p">)</span> <span class="p">(</span><span class="nx">builder</span> <span class="kd">interface</span><span class="p">{})</span> <span class="p">{</span>
    <span class="kd">var</span> <span class="nx">image</span> <span class="o">*</span><span class="nx">models</span><span class="p">.</span><span class="nx">Image</span>
    <span class="k">switch</span> <span class="nx">reqType</span> <span class="p">{</span>
    <span class="k">case</span> <span class="s">&quot;desktop&quot;</span><span class="p">:</span>
        <span class="nx">o</span> <span class="o">:=</span> <span class="o">&amp;</span><span class="nx">Original</span><span class="p">{</span><span class="nx">image</span><span class="p">}</span>
        <span class="nx">p</span> <span class="o">:=</span> <span class="o">&amp;</span><span class="nx">Preview</span><span class="p">{</span><span class="nx">image</span><span class="p">}</span>
        <span class="nx">t</span> <span class="o">:=</span> <span class="o">&amp;</span><span class="nx">Thumbnail</span><span class="p">{</span><span class="nx">image</span><span class="p">}</span>
        <span class="nx">builder</span> <span class="p">=</span> <span class="nx">Desktop</span><span class="p">{</span><span class="nx">o</span><span class="p">,</span> <span class="nx">p</span><span class="p">,</span> <span class="nx">t</span><span class="p">}</span>
    <span class="k">case</span> <span class="s">&quot;mobile&quot;</span><span class="p">:</span>
        <span class="nx">o</span> <span class="o">:=</span> <span class="o">&amp;</span><span class="nx">Original</span><span class="p">{</span><span class="nx">image</span><span class="p">}</span>
        <span class="nx">c</span> <span class="o">:=</span> <span class="o">&amp;</span><span class="nx">Cover</span><span class="p">{</span><span class="nx">image</span><span class="p">}</span>
        <span class="nx">builder</span> <span class="p">=</span> <span class="nx">Mobile</span><span class="p">{</span><span class="nx">o</span><span class="p">,</span> <span class="nx">c</span><span class="p">}</span>
    <span class="k">default</span><span class="p">:</span>
        <span class="nb">panic</span><span class="p">(</span><span class="s">&quot;Oooops, don&#39;t know which type it is!&quot;</span><span class="p">)</span>
    <span class="p">}</span>
    <span class="k">return</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nx">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="nx">reqType</span> <span class="o">:=</span> <span class="nx">GetRequestTypeFromNowhere</span><span class="p">()</span>  <span class="c1">// fake</span>
    <span class="nx">urlBuilder</span> <span class="o">:=</span> <span class="nx">GetUrlBuilder</span><span class="p">(</span><span class="nx">reqType</span><span class="p">)</span>
    <span class="k">switch</span> <span class="nx">reqType</span> <span class="p">{</span>
    <span class="k">case</span> <span class="s">&quot;desktop&quot;</span><span class="p">:</span>
        <span class="nx">urlBuilder</span><span class="p">.(</span><span class="nx">OriginalUrlBuilder</span><span class="p">).</span><span class="nx">OriginalUrl</span><span class="p">()</span>  <span class="c1">// original URL</span>
        <span class="nx">urlBuilder</span><span class="p">.(</span><span class="nx">PreviewUrlBuilder</span><span class="p">).</span><span class="nx">PreviewUrl</span><span class="p">()</span>  <span class="c1">// preview URL</span>
        <span class="nx">urlBuilder</span><span class="p">.(</span><span class="nx">ThumbnailUrlBuilder</span><span class="p">).</span><span class="nx">ThumbnailUrl</span><span class="p">()</span>  <span class="c1">// thumbnail URL</span>
    <span class="k">case</span> <span class="s">&quot;mobile&quot;</span><span class="p">:</span>
        <span class="nx">urlBuilder</span><span class="p">.(</span><span class="nx">OriginalUrlBuilder</span><span class="p">).</span><span class="nx">OriginalUrl</span><span class="p">()</span>  <span class="c1">// original URL</span>
        <span class="nx">urlBuilder</span><span class="p">.(</span><span class="nx">CoverUrlBuilder</span><span class="p">).</span><span class="nx">CoverUrl</span><span class="p">()</span>  <span class="c1">// cover URL</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div>


<p><code>GetUrlBuilder()</code> 返回 <code>interface{}</code>，即使用者不知道所返回的究竟是 <code>Desktop</code> 还是 <code>Mobile</code>。因为使用者只需负责使用就可以了，<code>desktop.(PreviewUrlBuilder).PreviewUrl()</code> 对所返回的 builder 先进行 type assertion 再调用相应 interface 中的方法，即我需要一个 preview URL 则我就调用 <code>PreviewUrlBuilder</code> 中的 <code>PreviewUrl()</code> 方法来获取这样一个 URL，除此以外我不需要知道其他任何信息，builder 的种类为何对使用者而言是透明的。而这也是最初声明四个不同基础 builder 的 interface 的好处之一。</p>

<p>最后总结一下这样的程序结构的优点：</p>

<ul>
<li>方便新增抽象分类，例如 <code>PadImageUrlBuilder</code>，使用基础的 builder 组合一下即可。</li>
<li>可根据需要实现多个同种基础 builder，只需实现其 interface 即可，在多个 builder 之间动态替换也没问题。</li>
<li>新增基础 builder 也很容易，声明 interface 并实现，然后在抽象分类中将其 embed 进去即可。</li>
<li>抽象分类对 builder 使用者完全透明，其只需 <code>GetUrlBuilder()</code> 后根据实际需要 type assertion 至相应基础 builder 并调用其方法即可，不需知道这是 desktop 还是 mobile builder。</li>
</ul>


<p>go 应用了这两条面向对象设计原则：</p>

<blockquote><ul>
<li>Favor composition over inheritance.</li>
<li>Program to an interface, not an implementation.</li>
</ul>
</blockquote>

<p>因此其虽非面向对象语言但是仍然有面向对象的痕迹，只是摒弃了设计者所不中意的部分（inheritance），并强调了他们喜欢的地方。在 go 中实现一个设计模式并非水到渠成的，但它所提供的概念及抽象总是在引导你试着去运用，明确地或是潜移默化地。</p>

<p>go 是给人一种相当朴素感觉的语言，当现代语言都在追求各种各样花哨形式（以给程序员提供乐趣，当然也确实很有乐趣）的时候，它仍以一种质朴平淡甚至近乎无聊的形式呈现自己，给你它所为你选择的它所认为重要的，显然漂亮的语法或 syntax sugar 并不在列，然而它居然也是有乐趣的，从少获得多，less is more，这也是另一种我所欣赏的审美态度。</p>

  </section>
</article>

  
  
  
<article role="article" class="well">
  <header>
    <section class="title">
      <h1>
        
        <a href="/2013/03/bioshock-infinite-brought-along/">『Bioshock Infinite』带来的</a>
        
      </h1>
    </section>
    <section class="meta">
      @<time>2013-03-26</time>
      <span class="categories">
        
        <em class="category">#game</em>
        
        <em class="category">#arts</em>
        
      </span>
    </section>
  </header>
  <section class="post">
    <p><img src="http://pic.yupoo.com/kols_v/CJWMsjZA/medium.jpg" alt="Bioshock Infinite" /></p>

<p>游戏作为艺术品是个矛盾体，它的意义需要娱乐来承载，虽然有些电影也是如此，但因为长度往往十个小时起算，因此在游戏中两者并不总是相容的。一点不娱乐的电影可称之为文艺片，但纯文艺而不娱乐大众的游戏估计从来就难以得见天日。因此 『Bioshock』 不断在枪林弹雨之间穿插 Voxophone 录音、Booker 与 Elizabeth 的互动、人性与宿命的考察，枪炮杀戮是前提，维持娱乐水准，后者是内涵，展现制作人真正想告诉你的东西。但由于时长问题，前者却一定是喧宾夺主地占据了玩家最大部分的时间——因此传言中 <abbr title="Metal Gear Solid 4">MGS 4</abbr> 大量过场剧情将玩家操作挤压至接近次要地位的情况，一定是小岛秀夫感受到了这种娱乐与内涵的不调和而做出的回应，但就是这样很简单（当然不简单）地将两者的比例改变一下，也会招致众多玩家的不满，因为游戏，它的第一要素依旧是玩（得爽）——而即使是这样，对于满足快感之余的叙事内容细节的考究、环环相扣的铺垫、精辟带有哲学意味的独白，仍然将整个作品的走向带至艺术品而非娱乐品的行列之中。</p>

<p>即便玩往往是肤浅的，但其体验并非一定与叙事、内涵相矛盾。『旺达与巨像』将对于故事的体验融入到了娱乐内容之中，你在巨像的庞大身躯上攀爬、跌落，狂奔、飞翔，这体验本身就是一种叙事，因为作者把你变成了旺达，你通过手柄感受他的艰难旅途，他甚至从头至尾都不曾说过一句话，让你除了他的肢体，再没有其他什么途径了解他的内心。沉默，往往就是这类游戏的基调，作者只给你一个大的环境与一些小的细节，剩下的全要由你想象，被引导的想象，发散的想象，满足的想象。</p>

<p>然而“娱乐，不论多么有趣，总会有一天厌倦。”这就是粘附在游戏这个想要成为艺术的载体身上的最为严重的缺陷。为了获得内心的感动，你不得不操纵你的角色先杀个尸横遍野，有时候这并不是多么愉快的体验，从而容易让人心生厌倦。电影中永远作为第三者的我们的视角在这时就很有优势，我不用承受任何负担，我可以跳过我不想要的，直入主题，获得满足。</p>

<p>游戏无法分离其表和里，为了得到一样就不能忽略另一样，两者的差异有时却又是如此得大以至于会让人有索性一并放弃的想法。这可能也就是为何游戏只是被戏称为第九艺术而从未真正被冠上艺术品之名的原因。</p>

  </section>
</article>

  
  
  
<article role="article" class="well">
  <header>
    <section class="title">
      <h1>
        
        <a href="/2013/03/motion-picture-diary-i/">电影日记 I</a>
        
      </h1>
    </section>
    <section class="meta">
      @<time>2013-03-09</time>
      <span class="categories">
        
        <em class="category">#motion picture</em>
        
      </span>
    </section>
  </header>
  <section class="post">
    <h2>Play It Again, Sam（呆头鹅）</h2>

<p>中译呆头鹅人如其名，伍迪艾伦把一个又傻又聪明的家伙演得相当神经质（敏感、多虑）
、话唠又不缺不动声色的幽默（“我二十九了，性能力高峰在十年前就结束了”；“不是焦虑
不是惊恐是 homosexual panic”…），说来这也是他的招牌演技了，只不过近年来水准下降
得厉害。向北非谍影借角色来做旁白虽然没法引起我的共鸣（没看过。。。），但却能把
剧情顺当地推进下去同时也有点人格分裂的意味，同时借他人之口来讲述自己的想法，不
会造成矛盾。戴安基顿这部片里长得有点奇怪，但那种呆呆的音调很有意思，同时衣着永
远有品位。虽然没有什么亮点但一演起对手戏就有种相当默契的感觉，不算话唠，但也喜
欢平静地一鸣惊人。她老公比较正常，同时也比较搞，随时报上所在地电话号码印象深刻
。快结束时那一段段臆想的剧情亮点颇多。结局稍有点首尾呼应。</p>

<h2>To Kill a Mocking Bird（杀死一只知更鸟）</h2>

<p>女孩 Scout 叫自己爸爸 Atticus 是让我觉得最棒的细节，一下子把她的天真无拘束和他
的平静稳定显露无遗。节奏很好，把这个伸张正义的片子拍得有点惊悚、有点悬疑又有点
悲哀。但不管怎么绕，父亲的正直，女孩和男孩的活泼，以及最后出场的人物那种让人惊
喜的善良（就像一只知更鸟）都被恰当表现了出来，不会头重脚轻虎头蛇尾。人性是丑恶
与美好并存的，然而即使是恶也并非总是纯粹的恶，而是被大势裹挟了的无知的恶。当嫌
疑人被关到镇里，镇上的居民被煽动想绕过法律直接制裁他，但勇敢的 Scout 的一席话就
改变了他们的态度，救了父亲，同时展现人们的矛盾。庭审是遗憾的，向我们展现了无论
哪个年代的人们都绕不过的那种不公的鄙夷与憎恶，以及努力了、捍卫了但又失败了的无
力。法庭辩论中张弛有度，不言自明的魅力被 Atticus 表现得淋漓尽致。</p>

<h2>I Confess（忏情记）</h2>

<p>恪守原则还是爱？不论哪个都需要勇气支撑。当女主角把一切和盘托出的时候，这个故事
落幕了还是刚刚开始？都不是，只是告诉你你的坦白真诚一文不名。为何探寻真相的人反
而要利用真相来达到自己的目的？因为掺杂了真相的谎言最容易生效。当一系列的巧合都
被联系到作为被告人的男主角身上时，他的沉默只是作为巧合的对立面的必然。当编剧觉
得巧合足够多的时候就给了观众一个解脱，但不那么自然，虽然我认为男主角的自我牺牲
如果真的能打动人，也就只能打动她了吧，以正确的方式。这就牵扯到另一个问题，你的
沉默别人不知缘由，就像你做了艰苦工作但没有人能够看得到，那它是白费了还是总在那
里等待别人的发现？电影说是后者。</p>

  </section>
</article>

  
  
  
<article role="article" class="well">
  <header>
    <section class="title">
      <h1>
        
        <a href="/2012/12/you-need-sunshine-boy/">You need sunshine boy</a>
        
      </h1>
    </section>
    <section class="meta">
      @<time>2012-12-25</time>
      <span class="categories">
        
        <em class="category">#photo</em>
        
      </span>
    </section>
  </header>
  <section class="post">
    <p><a href="http://500px.com/photo/21445079">
  <img class="oob" src="http://pcdn.500px.net/21445079/707294c5752a8f50b583d86f5732c2e4f39a04ab/4.jpg" alt="Wind by Kane Dou (kols)) on 500px.com" />
</a></p>

<p>you do need it (;</p>

  </section>
</article>

  
  
  
<article role="article" class="well">
  <header>
    <section class="title">
      <h1>
        
        <a href="/2012/07/introducing-python-scrapy-part-i/">使用 scrapy （Part I）</a>
        
      </h1>
    </section>
    <section class="meta">
      @<time>2012-07-18</time>
      <span class="categories">
        
        <em class="category">#python</em>
        
        <em class="category">#scrape</em>
        
        <em class="category">#crawl</em>
        
        <em class="category">#scrapy</em>
        
        <em class="category">#twisted</em>
        
      </span>
    </section>
  </header>
  <section class="post">
    <p><a href="http://scrapy.org">scrapy</a> 是一个高级的网页内容抓取工具，主要用来自动化访问网
页并程序化提取其中对用户有用的内容。scrapy 构建于流行的 python 异步框架
<a href="http://twistedmatrix.com">twisted</a> 之上，利用该框架的特点达到抓取的高效率，但
其面向用户的接口则是完全经过封装并与普通 python 代码写法并无二致的，因此不熟悉
twisted 的用户也不用担心。</p>

<!-- more -->


<h2>安装</h2>

<p>由于 scrapy 是一个 python package，所以先安装 virtualenv 及 pip：</p>

<div class="highlight"><pre><code class="sh"><span class="nv">$ </span>sudo apt-get install virtualenv python-pip
</code></pre></div>


<p>接着安装 scrapy：</p>

<div class="highlight"><pre><code class="sh"><span class="nv">$ </span>virtualenv --no-site-packages scrapy
<span class="nv">$ </span><span class="nb">source</span> ./scrapy/bin/activate
<span class="nv">$ </span>pip install scrapy
</code></pre></div>


<h2>使用</h2>

<p>scrapy 提供的各种工具能大量简化实际抓取时的代码量，同时其对抓取过程的抽象化也很
到位，方便用户对其控制的同时也提供了相当的自动化特性。</p>

<p>这里就用罗森的官方网站（http://www.lawson.com.cn/shops）为例，说明一下如何使用
scrapy。示例的结果是得到一份罗森在上海的所有便利店的清单。</p>

<h3>新建 Project</h3>

<p>首先用 scrapy 新建一个 project：</p>

<div class="highlight"><pre><code class="sh"><span class="nv">$ </span>scrapy startproject lawson
</code></pre></div>


<p>熟悉一下目录结构：</p>

<div class="highlight"><pre><code class="text">lawson
├── lawson
│   ├── __init__.py
│   ├── items.py
│   ├── pipelines.py
│   ├── settings.py
│   └── spiders
│       └── __init__.py
└── scrapy.cfg
</code></pre></div>


<ul>
<li><code>items.py</code> 定义抓取结果中单个项所需要包含的所有内容，比如便利店的地址、
分店名称等。</li>
<li><code>pipelines.py</code> 定义如何对抓取到的内容进行再处理，例如输出文件、写入数据库等。</li>
<li><code>settings.py</code> 是 scrapy 的设置文件，可对其行为进行调整。</li>
<li><code>spiders</code> 目录下存放写好的 spider，也即是实际抓取逻辑。</li>
<li><code>scrapy.cfg</code> 是整个项目的设置，主要用于部署 scrapyd 服务，本文不会涉及。</li>
</ul>


<h3>第一个 spider</h3>

<p>scrapy 中最为重要的部分就是
<a href="http://doc.scrapy.org/en/0.14/topics/spiders.html">spider</a>。它包含了
分析网页与抓取网页数据的具体逻辑，也就是说对网页上任何内容的任何处理都在 spider
中实现。因此，这是 scrapy 整个框架的核心。</p>

<p>首先定义
<a href="http://doc.scrapy.org/en/0.14/topics/items.html#module-scrapy.item">Item</a>：</p>

<div class="highlight"><pre><code class="python"><span class="kn">from</span> <span class="nn">scrapy.item</span> <span class="kn">import</span> <span class="n">Item</span><span class="p">,</span> <span class="n">Field</span>


<span class="k">class</span> <span class="nc">ConvStore</span><span class="p">(</span><span class="n">Item</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">branch</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">alias</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">address</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">city</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">district</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">longitude</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="n">serializer</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">latitude</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="n">serializer</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</code></pre></div>


<p>这里定义了一个便利店（<code>ConvStore</code>）所应包含的内容（
<a href="http://doc.scrapy.org/en/0.14/topics/items.html#item-fields">Field</a> ），会在
spider 中用到，用来承载其抓取下来的实际数据。</p>

<p>现在来看 spider：</p>

<div class="highlight"><pre><code class="python"><span class="kn">from</span> <span class="nn">scrapy.contrib.linkextractors.sgml</span> <span class="kn">import</span> <span class="n">SgmlLinkExtractor</span>
<span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">CrawlSpider</span><span class="p">,</span> <span class="n">Rule</span>
<span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">HtmlXPathSelector</span>

<span class="kn">from</span> <span class="nn">lawson.items</span> <span class="kn">import</span> <span class="n">ConvStore</span>


<span class="k">class</span> <span class="nc">LawsonSpider</span><span class="p">(</span><span class="n">CrawlSpider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&#39;lawson&#39;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.lawson.com.cn/shops&#39;</span><span class="p">]</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;lawson.com.cn&#39;</span><span class="p">]</span>
    <span class="n">rules</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">Rule</span><span class="p">(</span><span class="n">SgmlLinkExtractor</span><span class="p">(</span><span class="n">allow</span><span class="o">=</span><span class="s">r&#39;list\?area_id=\d+&#39;</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="s">&#39;a&#39;</span><span class="p">),</span>
                <span class="n">callback</span><span class="o">=</span><span class="s">&#39;parse_store_list&#39;</span><span class="p">),</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse_store_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">hxs</span> <span class="o">=</span> <span class="n">HtmlXPathSelector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="n">store_selectors</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;//div[@class=&quot;ShopList&quot;]/table/tr&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>

        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">store_selectors</span><span class="p">:</span>
            <span class="n">store</span> <span class="o">=</span> <span class="n">ConvStore</span><span class="p">()</span>
            <span class="n">store</span><span class="p">[</span><span class="s">&#39;name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s">u&#39;罗森&#39;</span>
            <span class="n">store</span><span class="p">[</span><span class="s">&#39;alias&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s">u&#39;Lawson&#39;</span>
            <span class="n">store</span><span class="p">[</span><span class="s">&#39;branch&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;th/p/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
            <span class="n">store</span><span class="p">[</span><span class="s">&#39;address&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;td/span/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
            <span class="n">store</span><span class="p">[</span><span class="s">&#39;district&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s">&#39;link_text&#39;</span><span class="p">]</span>
            <span class="n">store</span><span class="p">[</span><span class="s">&#39;city&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s">u&#39;上海&#39;</span>

            <span class="k">yield</span> <span class="n">store</span><span class="o">.</span><span class="n">load_item</span><span class="p">()</span>
</code></pre></div>


<ul>
<li>首先可以看到代码很短，整个 <code>LawsonSpider</code> 类只有二十多行，但已经能够为我们抓
取所有必需的信息。</li>
<li>scrapy 提供了一些基本类（Base class）让我们去继承，
<a href="http://doc.scrapy.org/en/0.14/topics/spiders.html#crawlspider"><code>CrawlSpider</code></a>
就是其中之一。代码中所定义的类变量（Class variable）都是再 scrapy 中有各自作
用的。

<ul>
<li><code>name</code> 是该 spider 的名字，scrapy 命令行工具调用 spider 时就用这个名字去找
到对应的 spider。</li>
<li><code>start_urls</code> 是 spider 的入口，即是告诉它该从哪个网页开始抓取。</li>
<li><code>allowed_domains</code> 限定 spider 的抓取活动只能在指定的 domain 中进行。</li>
</ul>
</li>
<li><code>rules</code> 定义了一系列规则用来匹配网页中出现的内容，并根据规则分发至不同的处理
方法中。这里定义了一个规则是向网页中所有匹配正则表达式 <code>r'list\?area_id=\d+'</code>
的链接（如果你在浏览器打开初始页面的话会发现这些就是页面下方以上海各个区命名
的那几个链接）发出请求并将其结果交给 <code>parse_store_list</code> 方法（Method）来处理。</li>
<li><a href="http://doc.scrapy.org/en/0.14/topics/link-extractors.html#sgmllinkextractor"><code>SgmlLinkExtractor</code></a>
是 scrapy 提供的连接提取器，它的用途就是，呃，提取链接。

<ul>
<li><code>allow</code> 参数是正则表达式，网页中匹配的链接会被抓取。</li>
<li><code>tags</code> 指定从哪些标签抓取链接，默认 <code>['a', 'area']</code>（通过分析网页
这里不能包含 <code>area</code>，故手动指定。</li>
</ul>
</li>
<li><code>parse_store_list</code> 方法定义了如何抓取特定网页中的数据

<ul>
<li><a href="http://doc.scrapy.org/en/0.14/topics/selectors.html#scrapy.selector.HtmlXPathSelector"><code>HtmlXPathSelector</code></a>
是一个选择器，使用它能方便地定位到网页中的某个位置并抓取其中内容。</li>
</ul>
</li>
</ul>


<h3><code>CrawlSpider</code></h3>

<p>这个类是整个抓取逻辑的基础，他的工作流程如下：</p>

<ol>
<li>若有 <code>start_urls</code>，则从这些 URL 开始抓取，若没有，则执行 <code>start_requests</code> 方
法（用户须定义），并请求该方法返回的 <code>Request</code> 对象，并从这些请求结果中开始
抓取。</li>
<li>所有网页请求返回的 <code>Response</code> 默认交给 <code>parse</code> 方法处理。

<ul>
<li><code>parse</code> 方法在 <code>CrawlSpider</code> 的默认实现是用已定义的 <code>rules</code> 对获得的网页内
容进行匹配并进行由 <code>Rule</code> 所指定的进一步处理（即交给 <code>callback</code> 参数所指定
的 <code>callable</code> 去处理）。</li>
<li>若不指定 <code>callback</code>, <code>Rule</code> 的默认处理是对匹配的网址发起请求，并再次交给
<code>parse</code>。</li>
</ul>
</li>
<li>任何方法中返回的 Item 实例（如示例中的 <code>ConvStore</code>）都会被作为有效数据保存
（输出文件等），再处理（
<a href="http://doc.scrapy.org/en/0.14/topics/item-pipeline.html">Pipeline</a>）。</li>
</ol>


<h3><code>HtmlXPathSelector</code></h3>

<p>这是一个通过 <a href="http://www.w3schools.com/xpath/default.asp">XPath</a> 对 HTML 页面进
行结构化定位和内容读取的工具。scrapy 使用它定位到网页中用户所需要的数据并进行抓
取。</p>

<div class="highlight"><pre><code class="python"><span class="k">def</span> <span class="nf">parse_store_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
    <span class="n">hxs</span> <span class="o">=</span> <span class="n">HtmlXPathSelector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
    <span class="n">store_selectors</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;//div[@class=&quot;ShopList&quot;]/table/tr&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>

    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">store_selectors</span><span class="p">:</span>
        <span class="o">...</span>
        <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;branch&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;th/p/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">())</span>
        <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;address&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;td/span/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">())</span>
        <span class="o">...</span>
</code></pre></div>


<ul>
<li><code>HtmlXPathSelector</code> 需要一个 Response 对象来实例化。</li>
<li><code>//div[@class="ShopList"]/table/tr</code> 选择了所有包含罗森门店信息的 <code>tr</code> 标签。</li>
<li><code>s.select('th/p/text()').extract()</code> 在之前的选择基础上继续对其子标签做选择，
这里就确实得选择到了分店名。<code>extract()</code> 则将该标签的文本数据读取出来。</li>
<li><code>HtmlXPathSelector</code> 还有正则表达式接口，后文会提到。</li>
</ul>


<h3>Field, Item 及 Item Loader</h3>

<p>Field 仅仅是一个 <code>dict</code> 的 wrapper 类，因此使用方法与 <code>dict</code> 完全一样，在
scrapy 中它负责声明单个 Item 的字段及该字段的各种行为（如序列化方法
<code>serializer</code>）。</p>

<p>Item 用 Field 定义了单个有效数据的具体字段，而实际中则是主要有两种方法写入
数据：</p>

<ol>
<li>使用其类似 <code>dict</code> 的接口进行数据的写入和读取，<code>key</code> 为字段名。</li>
<li>使用 <a href="http://doc.scrapy.org/en/0.14/topics/loaders.html">Item Loader</a>。</li>
</ol>


<p><code>dict</code> 接口的用法如上所示很简单，这里说一下 Item Loader。</p>

<div class="highlight"><pre><code class="python"><span class="kn">from</span> <span class="nn">scrapy.contrib.loader</span> <span class="kn">import</span> <span class="n">ItemLoader</span>
<span class="kn">from</span> <span class="nn">scrapy.contrib.loader.processor</span> <span class="kn">import</span> <span class="n">Compose</span>

<span class="kn">from</span> <span class="nn">lawson.items</span> <span class="kn">import</span> <span class="n">ConvStore</span>


<span class="k">class</span> <span class="nc">StoreLoader</span><span class="p">(</span><span class="n">ItemLoader</span><span class="p">):</span>
    <span class="n">default_output_processor</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">(</span><span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">unicode</span><span class="o">.</span><span class="n">strip</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">branch_in</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">yield</span> <span class="n">v</span> <span class="o">+</span> <span class="s">u&#39;店&#39;</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">v</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s">u&#39;店&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">v</span>


<span class="k">class</span> <span class="nc">LawsonSpider</span><span class="p">(</span><span class="n">CrawlSpider</span><span class="p">):</span>
    <span class="o">...</span>

    <span class="k">def</span> <span class="nf">parse_store_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">hxs</span> <span class="o">=</span> <span class="n">HtmlXPathSelector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="n">store_selectors</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;//div[@class=&quot;ShopList&quot;]/table/tr&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>

        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">store_selectors</span><span class="p">:</span>
            <span class="n">store</span> <span class="o">=</span> <span class="n">StoreLoader</span><span class="p">(</span><span class="n">item</span><span class="o">=</span><span class="n">ConvStore</span><span class="p">(),</span> <span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;name&#39;</span><span class="p">,</span> <span class="s">u&#39;罗森&#39;</span><span class="p">)</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;alias&#39;</span><span class="p">,</span> <span class="s">u&#39;Lawson&#39;</span><span class="p">)</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;branch&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;th/p/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">())</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;address&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;td/span/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">())</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;district&#39;</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s">&#39;link_text&#39;</span><span class="p">])</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;city&#39;</span><span class="p">,</span> <span class="s">u&#39;上海&#39;</span><span class="p">)</span>

            <span class="k">yield</span> <span class="n">store</span><span class="o">.</span><span class="n">load_item</span><span class="p">()</span>
</code></pre></div>


<p>Item Loader 的主要作用是对抓取数据的各个字段进行特殊处理，在这里我们定义了一个
<code>StoreLoader</code> 类继承（Inherit）自 <code>ItemLoader</code>：</p>

<ul>
<li><code>default_output_processor</code> 定义默认的输出处理器，这里我们对抓取的数据值进行
strip 操作。</li>
<li><code>branch_in</code> 方法是对 <code>branch</code> 字段的特殊处理，他发生在输入的时候，也就是刚抓
取到数据之后。这里的处理是为没有<code>店</code>这个字的分店名补上这个字。</li>
<li><code>&lt;field&gt;_in</code> 和 <code>&lt;field&gt;_out</code> 会各对指定字段做一次处理，前者是在刚抓取到数据
时，后者是在最终输出之前，用户根据需要定义相应方法。

<ul>
<li>scrapy 有一些 <a href="http://doc.scrapy.org/en/0.14/topics/loaders.html#module-scrapy.contrib.loader.processor">built-in processor</a>
可以直接使用，进行一些通用处理。</li>
</ul>
</li>
<li><code>add_value</code> 将值赋予相应字段，很好理解。</li>
<li><code>load_item</code> 返回该条填充过数据的 Item。</li>
</ul>


<p>使用 Item Loader 的好处显而易见，我们有一个统一的地方对所有数据字段进行处理，不
用将其混入抓取逻辑，使整个流程分工明确。</p>

<p>另一个常用的 Item Loader 是 <code>XPathItemLoader</code>，显然这个版本利用了 XPath：</p>

<div class="highlight"><pre><code class="python"><span class="n">store</span> <span class="o">=</span> <span class="n">XPathItemLoader</span><span class="p">(</span><span class="n">item</span><span class="o">=</span><span class="n">ConvStore</span><span class="p">(),</span> <span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
<span class="n">store</span><span class="o">.</span><span class="n">add_xpath</span><span class="p">(</span><span class="s">&#39;branch&#39;</span><span class="p">,</span> <span class="s">&#39;//div[@class=&quot;ShopList&quot;]/table/tr[2]/th/p/text()&#39;</span><span class="p">)</span>
</code></pre></div>


<p>它将字段与 XPath 表达式关联起来，直接完成定位、读取和写入数据的操作，很方便。</p>

<h3>加上经纬度</h3>

<p>经纬度对于定位一个地点是很有用的，通过电子地图能够精确地定位至相关地点。我发现
罗森网站提供了这个信息，但它并未明文显示，而是需要通过其所链接到的百度地图的页
面中去抓取下来，听起来很麻烦，但实际却很简单。</p>

<div class="highlight"><pre><code class="python"><span class="kn">from</span> <span class="nn">urlparse</span> <span class="kn">import</span> <span class="n">urljoin</span>

<span class="kn">from</span> <span class="nn">scrapy.contrib.loader</span> <span class="kn">import</span> <span class="n">XPathItemLoader</span>
<span class="kn">from</span> <span class="nn">scrapy.http</span> <span class="kn">import</span> <span class="n">Request</span>
<span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">HtmlXPathSelector</span>
<span class="kn">from</span> <span class="nn">scrapy.utils.response</span> <span class="kn">import</span> <span class="n">get_base_url</span>

<span class="kn">from</span> <span class="nn">poi_scrape.items</span> <span class="kn">import</span> <span class="n">ConvStore</span>


<span class="k">class</span> <span class="nc">StoreLoader</span><span class="p">(</span><span class="n">XPathItemLoader</span><span class="p">):</span>
    <span class="o">...</span>


<span class="k">class</span> <span class="nc">LawsonSpider</span><span class="p">(</span><span class="n">BasePoiSpider</span><span class="p">):</span>
    <span class="o">...</span>

    <span class="k">def</span> <span class="nf">parse_geo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">hxs</span> <span class="o">=</span> <span class="n">HtmlXPathSelector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="n">store</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s">&#39;store&#39;</span><span class="p">]</span>

        <span class="n">lng</span><span class="p">,</span> <span class="n">lat</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">re</span><span class="p">(</span><span class="s">r&#39;(\d+\.\d+),(\d+\.\d+)&#39;</span><span class="p">)</span>
        <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;latitude&#39;</span><span class="p">,</span> <span class="n">lat</span><span class="p">)</span>
        <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;longitude&#39;</span><span class="p">,</span> <span class="n">lng</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">store</span><span class="o">.</span><span class="n">load_item</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">parse_store_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="o">...</span>

        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">store_selectors</span><span class="p">:</span>
            <span class="n">store</span> <span class="o">=</span> <span class="n">StoreLoader</span><span class="p">(</span><span class="n">item</span><span class="o">=</span><span class="n">ConvStore</span><span class="p">(),</span> <span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
            <span class="o">...</span>

            <span class="n">map_rel_url</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;td/a/@rel&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">map_rel_url</span><span class="p">:</span>
                <span class="n">map_url</span> <span class="o">=</span> <span class="n">urljoin</span><span class="p">(</span><span class="n">get_base_url</span><span class="p">(</span><span class="n">response</span><span class="p">),</span> <span class="n">map_rel_url</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">req</span> <span class="o">=</span> <span class="n">Request</span><span class="p">(</span><span class="n">map_url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse_geo</span><span class="p">)</span>
                <span class="n">req</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s">&#39;store&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">store</span>
                <span class="k">yield</span> <span class="n">req</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">yield</span> <span class="n">store</span><span class="o">.</span><span class="n">load_item</span><span class="p">()</span>
</code></pre></div>


<p>这里为 <code>LawsonSpider</code> 新增了一个方法 <code>parse_geo</code>，同时改写了
<code>parse_store_list</code>。</p>

<ul>
<li>在 <code>parse_store_list</code> 的循环中我抓取每个店的 <code>tr</code> 标签中的 <code>td/a/@rel</code> 属性
（Attribute）（这里 <code>@rel</code> 表示 <code>a</code> 标签的 <code>rel</code> 属性），若有这一属性则对这个
地图的链接发起请求，即 <code>yield req</code>。

<ul>
<li>在 scrapy 中，spider 类中的方法若返回 Request 实例则 scrapy 会自动对该
Request 包含的 URL 发出请求，并将其返回的结果封装为 Response 后交给
<code>callback</code> 参数中指定的方法处理，若未指定 <code>callback</code>，则交给 <code>parse</code> 方法处
理。</li>
</ul>
</li>
<li><code>req.meta['store'] = store</code>，每个 Request 有一个预定义的 <code>meta</code> 属性（<code>dict</code>
），保存在其中的值在其对应的 Response 中可以再次取出：
<code>store = response.meta['store']</code>。</li>
<li><code>hxs.re(r'(\d+\.\d+),(\d+\.\d+)')</code> 使用了 <code>HtmlXPathSelector</code> 的正则表达式接
口直接从网页中通过正则表达式匹配抓取数据。</li>
</ul>


<h3>完整 spider 代码</h3>

<p><code>items.py</code> 没有改动，与上文中的一致。</p>

<div class="highlight"><pre><code class="python"><span class="c"># vim: fileencoding=utf-8</span>
<span class="kn">from</span> <span class="nn">urlparse</span> <span class="kn">import</span> <span class="n">urljoin</span>

<span class="kn">from</span> <span class="nn">scrapy.contrib.linkextractors.sgml</span> <span class="kn">import</span> <span class="n">SgmlLinkExtractor</span>
<span class="kn">from</span> <span class="nn">scrapy.contrib.loader</span> <span class="kn">import</span> <span class="n">XPathItemLoader</span>
<span class="kn">from</span> <span class="nn">scrapy.contrib.loader.processor</span> <span class="kn">import</span> <span class="n">Compose</span>
<span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">CrawlSpider</span><span class="p">,</span> <span class="n">Rule</span>
<span class="kn">from</span> <span class="nn">scrapy.http</span> <span class="kn">import</span> <span class="n">Request</span>
<span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">HtmlXPathSelector</span>
<span class="kn">from</span> <span class="nn">scrapy.utils.response</span> <span class="kn">import</span> <span class="n">get_base_url</span>

<span class="kn">from</span> <span class="nn">lawson.items</span> <span class="kn">import</span> <span class="n">ConvStore</span>


<span class="k">class</span> <span class="nc">StoreLoader</span><span class="p">(</span><span class="n">XPathItemLoader</span><span class="p">):</span>
    <span class="n">default_output_processor</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">(</span><span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">unicode</span><span class="o">.</span><span class="n">strip</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">branch_in</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">yield</span> <span class="n">v</span> <span class="o">+</span> <span class="s">u&#39;店&#39;</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">v</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s">u&#39;店&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">v</span>


<span class="k">class</span> <span class="nc">LawsonSpider</span><span class="p">(</span><span class="n">CrawlSpider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&#39;lawson&#39;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.lawson.com.cn/shops&#39;</span><span class="p">]</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;lawson.com.cn&#39;</span><span class="p">]</span>
    <span class="n">rules</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">Rule</span><span class="p">(</span><span class="n">SgmlLinkExtractor</span><span class="p">(</span><span class="n">allow</span><span class="o">=</span><span class="s">r&#39;list\?area_id=\d+&#39;</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="s">&#39;a&#39;</span><span class="p">),</span>
                <span class="n">callback</span><span class="o">=</span><span class="s">&#39;parse_store_list&#39;</span><span class="p">),</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse_geo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">hxs</span> <span class="o">=</span> <span class="n">HtmlXPathSelector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="n">store</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s">&#39;store&#39;</span><span class="p">]</span>

        <span class="n">lng</span><span class="p">,</span> <span class="n">lat</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">re</span><span class="p">(</span><span class="s">r&#39;(\d+\.\d+),(\d+\.\d+)&#39;</span><span class="p">)</span>
        <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;latitude&#39;</span><span class="p">,</span> <span class="n">lat</span><span class="p">)</span>
        <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;longitude&#39;</span><span class="p">,</span> <span class="n">lng</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">store</span><span class="o">.</span><span class="n">load_item</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">parse_store_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">hxs</span> <span class="o">=</span> <span class="n">HtmlXPathSelector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="n">store_selectors</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;//div[@class=&quot;ShopList&quot;]/table/tr&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>

        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">store_selectors</span><span class="p">:</span>
            <span class="n">store</span> <span class="o">=</span> <span class="n">StoreLoader</span><span class="p">(</span><span class="n">item</span><span class="o">=</span><span class="n">ConvStore</span><span class="p">(),</span> <span class="n">response</span><span class="o">=</span><span class="n">response</span><span class="p">)</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;name&#39;</span><span class="p">,</span> <span class="s">u&#39;罗森&#39;</span><span class="p">)</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;alias&#39;</span><span class="p">,</span> <span class="s">u&#39;Lawson&#39;</span><span class="p">)</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;branch&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;th/p/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">())</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;address&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;td/span/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">())</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;district&#39;</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s">&#39;link_text&#39;</span><span class="p">])</span>
            <span class="n">store</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s">&#39;city&#39;</span><span class="p">,</span> <span class="s">u&#39;上海&#39;</span><span class="p">)</span>

            <span class="n">map_rel_url</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;td/a/@rel&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">map_rel_url</span><span class="p">:</span>
                <span class="n">map_url</span> <span class="o">=</span> <span class="n">urljoin</span><span class="p">(</span><span class="n">get_base_url</span><span class="p">(</span><span class="n">response</span><span class="p">),</span> <span class="n">map_rel_url</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">req</span> <span class="o">=</span> <span class="n">Request</span><span class="p">(</span><span class="n">map_url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse_geo</span><span class="p">)</span>
                <span class="n">req</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s">&#39;store&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">store</span>
                <span class="k">yield</span> <span class="n">req</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">yield</span> <span class="n">store</span><span class="o">.</span><span class="n">load_item</span><span class="p">()</span>
</code></pre></div>


<h3>scrapy 命令行工具</h3>

<p>scrapy 提供了一些命令行工具
（<a href="http://doc.scrapy.org/en/0.14/topics/commands.html">Command line tool</a>），之
前创建 Project 的时候用到的 <code>startproject</code> 就是其中之一。而除了这个之外，其他工
具也各自提供了相当有用的功能。</p>

<div class="highlight"><pre><code class="text">$ scrapy
Scrapy 0.14.4 - project: lawson

Usage:
  scrapy &lt;command&gt; [options] [args]

Available commands:
  crawl         Start crawling from a spider or URL
  deploy        Deploy project in Scrapyd target
  edit          Edit spider
  fetch         Fetch a URL using the Scrapy downloader
  genspider     Generate new spider using pre-defined templates
  list          List available spiders
  parse         Parse URL (using its spider) and print the results
  runspider     Run a self-contained spider (without creating a project)
  server        Start Scrapyd server for this project
  settings      Get settings values
  shell         Interactive scraping console
  startproject  Create new project
  version       Print Scrapy version
  view          Open URL in browser, as seen by Scrapy

Use &quot;scrapy &lt;command&gt; -h&quot; to see more info about a command
</code></pre></div>


<p>这里仅挑出部分来讲。</p>

<h4><code>shell</code></h4>

<div class="highlight"><pre><code class="sh"><span class="nv">$ </span>scrapy shell <span class="s1">&#39;http://www.lawson.com.cn/shops&#39;</span>
</code></pre></div>


<p>运行后会进入 Python Interpreter，在这里我们能进行各种试验，配合
<a href="http://doc.scrapy.org/en/0.14/topics/firebug.html">Firebug</a> 之类的工具，为程序
构建一个原型：</p>

<ul>
<li>抓取各区分店列表链接，同时演示 <code>SgmlLInkExtractor</code> 用法：</li>
</ul>


<div class="highlight"><pre><code class="python"><span class="n">In</span> <span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="kn">from</span> <span class="nn">scrapy.contrib.linkextractors.sgml</span> <span class="kn">import</span> <span class="n">SgmlLinkExtractor</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">SgmlLinkExtractor</span><span class="p">(</span><span class="n">allow</span><span class="o">=</span><span class="s">r&#39;list\?area_id=\d+&#39;</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="s">&#39;a&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract_links</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
<span class="p">[</span><span class="n">Link</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="s">&#39;http://www.lawson.com.cn/shops/list?area_id=1&#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s">u&#39;</span><span class="se">\u957f\u5b81\u533a</span><span class="s">&#39;</span><span class="p">,</span> <span class="n">fragment</span><span class="o">=</span><span class="s">&#39;&#39;</span><span class="p">,</span> <span class="n">nofollow</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
 <span class="n">Link</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="s">&#39;http://www.lawson.com.cn/shops/list?area_id=2&#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s">u&#39;</span><span class="se">\u5f90\u6c47\u533a</span><span class="s">&#39;</span><span class="p">,</span> <span class="n">fragment</span><span class="o">=</span><span class="s">&#39;&#39;</span><span class="p">,</span> <span class="n">nofollow</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
 <span class="n">Link</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="s">&#39;http://www.lawson.com.cn/shops/list?area_id=3&#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s">u&#39;</span><span class="se">\u9759\u5b89\u533a</span><span class="s">&#39;</span><span class="p">,</span> <span class="n">fragment</span><span class="o">=</span><span class="s">&#39;&#39;</span><span class="p">,</span> <span class="n">nofollow</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
 <span class="o">...</span>
</code></pre></div>


<ul>
<li>抓取分店列表，<code>fetch</code> 用来载入新的 URL：</li>
</ul>


<div class="highlight"><pre><code class="python"><span class="n">In</span> <span class="p">[</span><span class="mi">6</span><span class="p">]:</span> <span class="n">fetch</span><span class="p">(</span><span class="s">&#39;http://www.lawson.com.cn/shops/list?area_id=1&#39;</span><span class="p">)</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">7</span><span class="p">]:</span> <span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;//div[@class=&quot;ShopList&quot;]/table/tr&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">7</span><span class="p">]:</span>
<span class="p">[</span><span class="o">&lt;</span><span class="n">HtmlXPathSelector</span> <span class="n">xpath</span><span class="o">=</span><span class="s">&#39;//div[@class=&quot;ShopList&quot;]/table/tr&#39;</span> <span class="n">data</span><span class="o">=</span><span class="s">u&#39;&lt;tr&gt;&lt;th scope=&quot;row&quot; class=&quot;linetop&quot;&gt;</span><span class="se">\n\t\t\t</span><span class="s">&#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="n">HtmlXPathSelector</span> <span class="n">xpath</span><span class="o">=</span><span class="s">&#39;//div[@class=&quot;ShopList&quot;]/table/tr&#39;</span> <span class="n">data</span><span class="o">=</span><span class="s">u&#39;&lt;tr&gt;&lt;th scope=&quot;row&quot; class=&quot;linetop&quot;&gt;</span><span class="se">\n\t\t\t</span><span class="s">&#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">&lt;</span><span class="n">HtmlXPathSelector</span> <span class="n">xpath</span><span class="o">=</span><span class="s">&#39;//div[@class=&quot;ShopList&quot;]/table/tr&#39;</span> <span class="n">data</span><span class="o">=</span><span class="s">u&#39;&lt;tr&gt;&lt;th scope=&quot;row&quot; class=&quot;linetop&quot;&gt;</span><span class="se">\n\t\t\t</span><span class="s">&#39;</span><span class="o">&gt;</span><span class="p">,</span>
 <span class="o">...</span><span class="p">]</span>
</code></pre></div>


<ul>
<li>抓取分店名称，演示 <code>HtmlXPathSelector</code> 用法：</li>
</ul>


<div class="highlight"><pre><code class="python"><span class="n">In</span> <span class="p">[</span><span class="mi">8</span><span class="p">]:</span> <span class="n">s</span> <span class="o">=</span> <span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;//div[@class=&quot;ShopList&quot;]/table/tr&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:][</span><span class="mi">0</span><span class="p">]</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">9</span><span class="p">]:</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;th/p/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
<span class="n">Out</span><span class="p">[</span><span class="mi">9</span><span class="p">]:</span> <span class="p">[</span><span class="s">u&#39;</span><span class="se">\n\t\t\t\t\u53e4\u5317\u65b0\u533a\n\t\t\t\t</span><span class="s">&#39;</span><span class="p">]</span>

<span class="n">In</span> <span class="p">[</span><span class="mi">11</span><span class="p">]:</span> <span class="k">print</span> <span class="n">s</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&#39;th/p/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">+</span> <span class="s">u&#39;店&#39;</span>
<span class="err">古北新区店</span>
</code></pre></div>


<p>这是一个相当完善的命令行界面，提供了所有必需的网页分析及抓取工具，十分适合在实
际写抓取程序前做实验。</p>

<p>而 <code>shell</code> 不仅能从命令行直接调用，还能从程序中调用直接进入以便分析程序做调试：</p>

<div class="highlight"><pre><code class="python"><span class="kn">from</span> <span class="nn">scrapy.shell</span> <span class="kn">import</span> <span class="n">inspect_response</span>


<span class="k">class</span> <span class="nc">LawsonSpider</span><span class="p">(</span><span class="n">BasePoiSpider</span><span class="p">):</span>
    <span class="o">...</span>

    <span class="k">def</span> <span class="nf">parse_geo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">inspect_response</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse_store_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="o">...</span>
</code></pre></div>


<p>这样在执行到 <code>parse_geo</code> 时就会掉入 <code>shell</code> 界面，可以做进一步调试。</p>

<h4><code>crawl</code></h4>

<p>真正的抓取就是通过这个命令执行的：</p>

<div class="highlight"><pre><code class="sh"><span class="nv">$ </span>scrapy crawl lawson
</code></pre></div>




<div class="highlight"><pre><code class="text">2012-07-18 15:14:58+0800 [scrapy] INFO: Scrapy 0.14.4 started (bot: lawson)
2012-07-18 15:14:58+0800 [scrapy] DEBUG: Enabled extensions: FeedExporter, LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2012-07-18 15:14:58+0800 [scrapy] DEBUG: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, RedirectMiddleware, CookiesMiddleware, HttpCompressionMiddleware, ChunkedTransferMiddleware, DownloaderStats
2012-07-18 15:14:58+0800 [scrapy] DEBUG: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2012-07-18 15:14:58+0800 [scrapy] DEBUG: Enabled item pipelines:
2012-07-18 15:14:58+0800 [lawson] INFO: Spider opened
2012-07-18 15:14:58+0800 [lawson] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2012-07-18 15:14:58+0800 [scrapy] DEBUG: Telnet console listening on 0.0.0.0:6023
2012-07-18 15:14:58+0800 [scrapy] DEBUG: Web service listening on 0.0.0.0:6080
2012-07-18 15:14:59+0800 [lawson] DEBUG: Crawled (200) &lt;GET http://www.lawson.com.cn/shops&gt; (referer: None)
2012-07-18 15:14:59+0800 [lawson] DEBUG: Crawled (200) &lt;GET http://www.lawson.com.cn/shops/list?area_id=16&gt; (referer: http://www.lawson.com.cn/shops)
2012-07-18 15:14:59+0800 [lawson] DEBUG: Scraped from &lt;200 http://www.lawson.com.cn/shops/list?area_id=16&gt;
    {&#39;address&#39;: u&#39;\u5609\u5b9a\u533a\u5609\u677e\u516c\u8def6128\u53f7&#39;,
     &#39;alias&#39;: u&#39;Lawson&#39;,
     &#39;branch&#39;: u&#39;\u540c\u6d4e\u5927\u5b66\u5e97&#39;,
     &#39;city&#39;: u&#39;\u4e0a\u6d77&#39;,
     &#39;district&#39;: u&#39;\u5609\u5b9a\u533a&#39;,
     &#39;name&#39;: u&#39;\u7f57\u68ee&#39;}
...
2012-07-18 15:15:01+0800 [lawson] DEBUG: Crawled (200) &lt;GET http://www.lawson.com.cn/shops/199/map&gt; (referer: http://www.lawson.com.cn/shops/list?area_id=12)
2012-07-18 15:15:01+0800 [lawson] DEBUG: Scraped from &lt;200 http://www.lawson.com.cn/shops/199/map&gt;
    {&#39;address&#39;: u&#39;\u677e\u6c5f\u533a\u897f\u6797\u5317\u8def1048\u53f7&#39;,
     &#39;alias&#39;: u&#39;Lawson&#39;,
     &#39;branch&#39;: u&#39;\u677e\u6c5f\u5987\u5e7c\u4fdd\u5065\u9662\u5e97&#39;,
     &#39;city&#39;: u&#39;\u4e0a\u6d77&#39;,
     &#39;district&#39;: u&#39;\u677e\u6c5f\u533a&#39;,
     &#39;latitude&#39;: u&#39;31.030622&#39;,
     &#39;longitude&#39;: u&#39;121.225586&#39;,
     &#39;name&#39;: u&#39;\u7f57\u68ee&#39;}
...
2012-07-18 15:15:21+0800 [lawson] INFO: Closing spider (finished)
2012-07-18 15:15:21+0800 [lawson] INFO: Stored csv feed (320 items) in: lawson_store.csv
2012-07-18 15:15:21+0800 [lawson] INFO: Dumping spider stats:
    {&#39;downloader/request_bytes&#39;: 158946,
     &#39;downloader/request_count&#39;: 309,
     &#39;downloader/request_method_count/GET&#39;: 309,
     &#39;downloader/response_bytes&#39;: 1883104,
     &#39;downloader/response_count&#39;: 309,
     &#39;downloader/response_status_count/200&#39;: 309,
     &#39;finish_reason&#39;: &#39;finished&#39;,
     &#39;finish_time&#39;: datetime.datetime(2012, 7, 18, 7, 15, 21, 905140),
     &#39;item_scraped_count&#39;: 320,
     &#39;request_depth_max&#39;: 2,
     &#39;scheduler/memory_enqueued&#39;: 309,
     &#39;start_time&#39;: datetime.datetime(2012, 7, 18, 7, 14, 58, 538838)}
2012-07-18 15:15:21+0800 [lawson] INFO: Spider closed (finished)
2012-07-18 15:15:21+0800 [scrapy] INFO: Dumping global stats:
    {}
</code></pre></div>


<p>从最后的报告中可以看到这个 spider 在一分钟内抓取了该网站全部320条数据
（<code>item_scraped_count</code>）。</p>

<p>若要输出抓取结果到一个文件，则加上参数：</p>

<div class="highlight"><pre><code class="sh">scrapy crawl lawson -o store.csv -t csv
</code></pre></div>


<p>这样，这篇 scrapy 使用教程的第一部分就结束了。</p>

  </section>
</article>

  
  <div class="more-archive">
    
    <a href="/archive.html"><div class="circle">&nbsp;</div></a>
    
  </div>
</div>

      </div>
      <footer role="contentinfo" class="contentinfo">
        <div>
  
  
  <span class="copy">&copy; 2004-2013 kane</span>
  |
  <span class="license">
    <a href="http://creativecommons.org/licenses/by/3.0/cn/">license</a>
  </span>
  |
  <span class="engine">
    powered by <a href="http://jekyllrb.com/">jekyll</a> & <a href="http://compass-style.org">compass</a>
  </span>
</div>

      </footer>
    </div>
  </body>
</html>
